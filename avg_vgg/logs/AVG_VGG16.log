Logging output to avg_vgg/logs/AVG_VGG16.log
I0210 15:53:24.626185 27601 caffe.cpp:185] Using GPUs 6, 7
I0210 15:53:25.106616 27601 caffe.cpp:190] GPU 6: Tesla K80
I0210 15:53:25.109033 27601 caffe.cpp:190] GPU 7: Tesla K80
I0210 15:53:25.706766 27601 solver.cpp:48] Initializing solver from parameters: 
test_iter: 2897
test_interval: 188
base_lr: 0.001
display: 20
max_iter: 3948
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 3948
snapshot_prefix: "/opt/luojh/Net-Compression/value_sum/CUB200/1_ft_avg_vgg/avg_vgg/snapshot/"
solver_mode: GPU
device_id: 6
net: "/opt/luojh/Net-Compression/value_sum/CUB200/1_ft_avg_vgg/avg_vgg/trainval.prototxt"
test_initialization: false
stepvalue: 1316
stepvalue: 2632
I0210 15:53:25.719936 27601 solver.cpp:91] Creating training net from net file: /opt/luojh/Net-Compression/value_sum/CUB200/1_ft_avg_vgg/avg_vgg/trainval.prototxt
I0210 15:53:25.721456 27601 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0210 15:53:25.722072 27601 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 110
    mean_value: 127
    mean_value: 123
  }
  data_param {
    source: "/opt/luojh/Dataset/CUB/LMDB/cub200_2011_train_lmdb"
    batch_size: 16
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "relu1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "relu1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "relu1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "relu2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "relu2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "relu2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "relu3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "relu3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "relu3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "relu3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "relu3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "relu3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "relu4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "relu4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "relu4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "relu4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "relu4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "relu4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "relu5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "relu5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "relu5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "relu5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "relu5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5_3"
  top: "pool5"
  pooling_param {
    pool: AVE
    kernel_size: 14
    stride: 1
  }
}
layer {
  name: "softmax"
  type: "Convolution"
  bottom: "pool5"
  top: "softmax"
  param {
    lr_mult: 10
    decay_mult: 10
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  convolution_param {
    num_output: 200
    kernel_size: 1
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "softmax"
  bottom: "label"
  top: "loss"
}
layer {
  name: "acc_top_1"
  type: "Accuracy"
  bottom: "softmax"
  bottom: "label"
  top: "acc_top_1"
  accuracy_param {
    top_k: 1
  }
}
I0210 15:53:25.722358 27601 layer_factory.hpp:77] Creating layer data
I0210 15:53:25.722877 27601 net.cpp:91] Creating Layer data
I0210 15:53:25.722893 27601 net.cpp:399] data -> data
I0210 15:53:25.722965 27601 net.cpp:399] data -> label
I0210 15:53:25.769906 27606 db_lmdb.cpp:35] Opened lmdb /opt/luojh/Dataset/CUB/LMDB/cub200_2011_train_lmdb
I0210 15:53:25.805263 27601 data_layer.cpp:41] output data size: 16,3,224,224
I0210 15:53:25.824585 27601 net.cpp:141] Setting up data
I0210 15:53:25.824618 27601 net.cpp:148] Top shape: 16 3 224 224 (2408448)
I0210 15:53:25.824625 27601 net.cpp:148] Top shape: 16 (16)
I0210 15:53:25.824630 27601 net.cpp:156] Memory required for data: 9633856
I0210 15:53:25.824643 27601 layer_factory.hpp:77] Creating layer label_data_1_split
I0210 15:53:25.824656 27601 net.cpp:91] Creating Layer label_data_1_split
I0210 15:53:25.824661 27601 net.cpp:425] label_data_1_split <- label
I0210 15:53:25.824678 27601 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0210 15:53:25.824689 27601 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0210 15:53:25.824769 27601 net.cpp:141] Setting up label_data_1_split
I0210 15:53:25.824780 27601 net.cpp:148] Top shape: 16 (16)
I0210 15:53:25.824784 27601 net.cpp:148] Top shape: 16 (16)
I0210 15:53:25.824806 27601 net.cpp:156] Memory required for data: 9633984
I0210 15:53:25.824810 27601 layer_factory.hpp:77] Creating layer conv1_1
I0210 15:53:25.824826 27601 net.cpp:91] Creating Layer conv1_1
I0210 15:53:25.824829 27601 net.cpp:425] conv1_1 <- data
I0210 15:53:25.824836 27601 net.cpp:399] conv1_1 -> conv1_1
I0210 15:53:25.834090 27607 blocking_queue.cpp:50] Waiting for data
I0210 15:53:26.023404 27601 net.cpp:141] Setting up conv1_1
I0210 15:53:26.023444 27601 net.cpp:148] Top shape: 16 64 224 224 (51380224)
I0210 15:53:26.023449 27601 net.cpp:156] Memory required for data: 215154880
I0210 15:53:26.023468 27601 layer_factory.hpp:77] Creating layer relu1_1
I0210 15:53:26.023480 27601 net.cpp:91] Creating Layer relu1_1
I0210 15:53:26.023485 27601 net.cpp:425] relu1_1 <- conv1_1
I0210 15:53:26.023491 27601 net.cpp:399] relu1_1 -> relu1_1
I0210 15:53:26.023661 27601 net.cpp:141] Setting up relu1_1
I0210 15:53:26.023672 27601 net.cpp:148] Top shape: 16 64 224 224 (51380224)
I0210 15:53:26.023676 27601 net.cpp:156] Memory required for data: 420675776
I0210 15:53:26.023679 27601 layer_factory.hpp:77] Creating layer conv1_2
I0210 15:53:26.023692 27601 net.cpp:91] Creating Layer conv1_2
I0210 15:53:26.023697 27601 net.cpp:425] conv1_2 <- relu1_1
I0210 15:53:26.023703 27601 net.cpp:399] conv1_2 -> conv1_2
I0210 15:53:26.024648 27601 net.cpp:141] Setting up conv1_2
I0210 15:53:26.024663 27601 net.cpp:148] Top shape: 16 64 224 224 (51380224)
I0210 15:53:26.024678 27601 net.cpp:156] Memory required for data: 626196672
I0210 15:53:26.024688 27601 layer_factory.hpp:77] Creating layer relu1_2
I0210 15:53:26.024694 27601 net.cpp:91] Creating Layer relu1_2
I0210 15:53:26.024698 27601 net.cpp:425] relu1_2 <- conv1_2
I0210 15:53:26.024703 27601 net.cpp:399] relu1_2 -> relu1_2
I0210 15:53:26.025014 27601 net.cpp:141] Setting up relu1_2
I0210 15:53:26.025028 27601 net.cpp:148] Top shape: 16 64 224 224 (51380224)
I0210 15:53:26.025032 27601 net.cpp:156] Memory required for data: 831717568
I0210 15:53:26.025035 27601 layer_factory.hpp:77] Creating layer pool1
I0210 15:53:26.025045 27601 net.cpp:91] Creating Layer pool1
I0210 15:53:26.025049 27601 net.cpp:425] pool1 <- relu1_2
I0210 15:53:26.025054 27601 net.cpp:399] pool1 -> pool1
I0210 15:53:26.025102 27601 net.cpp:141] Setting up pool1
I0210 15:53:26.025111 27601 net.cpp:148] Top shape: 16 64 112 112 (12845056)
I0210 15:53:26.025115 27601 net.cpp:156] Memory required for data: 883097792
I0210 15:53:26.025117 27601 layer_factory.hpp:77] Creating layer conv2_1
I0210 15:53:26.025125 27601 net.cpp:91] Creating Layer conv2_1
I0210 15:53:26.025128 27601 net.cpp:425] conv2_1 <- pool1
I0210 15:53:26.025133 27601 net.cpp:399] conv2_1 -> conv2_1
I0210 15:53:26.027911 27601 net.cpp:141] Setting up conv2_1
I0210 15:53:26.027925 27601 net.cpp:148] Top shape: 16 128 112 112 (25690112)
I0210 15:53:26.027941 27601 net.cpp:156] Memory required for data: 985858240
I0210 15:53:26.027951 27601 layer_factory.hpp:77] Creating layer relu2_1
I0210 15:53:26.027958 27601 net.cpp:91] Creating Layer relu2_1
I0210 15:53:26.027962 27601 net.cpp:425] relu2_1 <- conv2_1
I0210 15:53:26.027967 27601 net.cpp:399] relu2_1 -> relu2_1
I0210 15:53:26.028129 27601 net.cpp:141] Setting up relu2_1
I0210 15:53:26.028139 27601 net.cpp:148] Top shape: 16 128 112 112 (25690112)
I0210 15:53:26.028143 27601 net.cpp:156] Memory required for data: 1088618688
I0210 15:53:26.028151 27601 layer_factory.hpp:77] Creating layer conv2_2
I0210 15:53:26.028159 27601 net.cpp:91] Creating Layer conv2_2
I0210 15:53:26.028163 27601 net.cpp:425] conv2_2 <- relu2_1
I0210 15:53:26.028169 27601 net.cpp:399] conv2_2 -> conv2_2
I0210 15:53:26.029216 27601 net.cpp:141] Setting up conv2_2
I0210 15:53:26.029229 27601 net.cpp:148] Top shape: 16 128 112 112 (25690112)
I0210 15:53:26.029245 27601 net.cpp:156] Memory required for data: 1191379136
I0210 15:53:26.029251 27601 layer_factory.hpp:77] Creating layer relu2_2
I0210 15:53:26.029258 27601 net.cpp:91] Creating Layer relu2_2
I0210 15:53:26.029261 27601 net.cpp:425] relu2_2 <- conv2_2
I0210 15:53:26.029289 27601 net.cpp:399] relu2_2 -> relu2_2
I0210 15:53:26.029444 27601 net.cpp:141] Setting up relu2_2
I0210 15:53:26.029454 27601 net.cpp:148] Top shape: 16 128 112 112 (25690112)
I0210 15:53:26.029458 27601 net.cpp:156] Memory required for data: 1294139584
I0210 15:53:26.029461 27601 layer_factory.hpp:77] Creating layer pool2
I0210 15:53:26.029467 27601 net.cpp:91] Creating Layer pool2
I0210 15:53:26.029471 27601 net.cpp:425] pool2 <- relu2_2
I0210 15:53:26.029475 27601 net.cpp:399] pool2 -> pool2
I0210 15:53:26.029513 27601 net.cpp:141] Setting up pool2
I0210 15:53:26.029520 27601 net.cpp:148] Top shape: 16 128 56 56 (6422528)
I0210 15:53:26.029523 27601 net.cpp:156] Memory required for data: 1319829696
I0210 15:53:26.029527 27601 layer_factory.hpp:77] Creating layer conv3_1
I0210 15:53:26.029534 27601 net.cpp:91] Creating Layer conv3_1
I0210 15:53:26.029541 27601 net.cpp:425] conv3_1 <- pool2
I0210 15:53:26.029546 27601 net.cpp:399] conv3_1 -> conv3_1
I0210 15:53:26.031512 27601 net.cpp:141] Setting up conv3_1
I0210 15:53:26.031525 27601 net.cpp:148] Top shape: 16 256 56 56 (12845056)
I0210 15:53:26.031541 27601 net.cpp:156] Memory required for data: 1371209920
I0210 15:53:26.031553 27601 layer_factory.hpp:77] Creating layer relu3_1
I0210 15:53:26.031559 27601 net.cpp:91] Creating Layer relu3_1
I0210 15:53:26.031563 27601 net.cpp:425] relu3_1 <- conv3_1
I0210 15:53:26.031569 27601 net.cpp:399] relu3_1 -> relu3_1
I0210 15:53:26.031906 27601 net.cpp:141] Setting up relu3_1
I0210 15:53:26.031919 27601 net.cpp:148] Top shape: 16 256 56 56 (12845056)
I0210 15:53:26.031922 27601 net.cpp:156] Memory required for data: 1422590144
I0210 15:53:26.031926 27601 layer_factory.hpp:77] Creating layer conv3_2
I0210 15:53:26.031936 27601 net.cpp:91] Creating Layer conv3_2
I0210 15:53:26.031940 27601 net.cpp:425] conv3_2 <- relu3_1
I0210 15:53:26.031949 27601 net.cpp:399] conv3_2 -> conv3_2
I0210 15:53:26.034694 27601 net.cpp:141] Setting up conv3_2
I0210 15:53:26.034719 27601 net.cpp:148] Top shape: 16 256 56 56 (12845056)
I0210 15:53:26.034723 27601 net.cpp:156] Memory required for data: 1473970368
I0210 15:53:26.034730 27601 layer_factory.hpp:77] Creating layer relu3_2
I0210 15:53:26.034739 27601 net.cpp:91] Creating Layer relu3_2
I0210 15:53:26.034741 27601 net.cpp:425] relu3_2 <- conv3_2
I0210 15:53:26.034749 27601 net.cpp:399] relu3_2 -> relu3_2
I0210 15:53:26.034920 27601 net.cpp:141] Setting up relu3_2
I0210 15:53:26.034930 27601 net.cpp:148] Top shape: 16 256 56 56 (12845056)
I0210 15:53:26.034934 27601 net.cpp:156] Memory required for data: 1525350592
I0210 15:53:26.034937 27601 layer_factory.hpp:77] Creating layer conv3_3
I0210 15:53:26.034947 27601 net.cpp:91] Creating Layer conv3_3
I0210 15:53:26.034952 27601 net.cpp:425] conv3_3 <- relu3_2
I0210 15:53:26.034960 27601 net.cpp:399] conv3_3 -> conv3_3
I0210 15:53:26.037654 27601 net.cpp:141] Setting up conv3_3
I0210 15:53:26.037669 27601 net.cpp:148] Top shape: 16 256 56 56 (12845056)
I0210 15:53:26.037673 27601 net.cpp:156] Memory required for data: 1576730816
I0210 15:53:26.037679 27601 layer_factory.hpp:77] Creating layer relu3_3
I0210 15:53:26.037688 27601 net.cpp:91] Creating Layer relu3_3
I0210 15:53:26.037691 27601 net.cpp:425] relu3_3 <- conv3_3
I0210 15:53:26.037696 27601 net.cpp:399] relu3_3 -> relu3_3
I0210 15:53:26.038218 27601 net.cpp:141] Setting up relu3_3
I0210 15:53:26.038231 27601 net.cpp:148] Top shape: 16 256 56 56 (12845056)
I0210 15:53:26.038246 27601 net.cpp:156] Memory required for data: 1628111040
I0210 15:53:26.038249 27601 layer_factory.hpp:77] Creating layer pool3
I0210 15:53:26.038256 27601 net.cpp:91] Creating Layer pool3
I0210 15:53:26.038261 27601 net.cpp:425] pool3 <- relu3_3
I0210 15:53:26.038269 27601 net.cpp:399] pool3 -> pool3
I0210 15:53:26.038310 27601 net.cpp:141] Setting up pool3
I0210 15:53:26.038316 27601 net.cpp:148] Top shape: 16 256 28 28 (3211264)
I0210 15:53:26.038319 27601 net.cpp:156] Memory required for data: 1640956096
I0210 15:53:26.038322 27601 layer_factory.hpp:77] Creating layer conv4_1
I0210 15:53:26.038344 27601 net.cpp:91] Creating Layer conv4_1
I0210 15:53:26.038348 27601 net.cpp:425] conv4_1 <- pool3
I0210 15:53:26.038355 27601 net.cpp:399] conv4_1 -> conv4_1
I0210 15:53:26.043197 27601 net.cpp:141] Setting up conv4_1
I0210 15:53:26.043212 27601 net.cpp:148] Top shape: 16 512 28 28 (6422528)
I0210 15:53:26.043216 27601 net.cpp:156] Memory required for data: 1666646208
I0210 15:53:26.043222 27601 layer_factory.hpp:77] Creating layer relu4_1
I0210 15:53:26.043228 27601 net.cpp:91] Creating Layer relu4_1
I0210 15:53:26.043232 27601 net.cpp:425] relu4_1 <- conv4_1
I0210 15:53:26.043237 27601 net.cpp:399] relu4_1 -> relu4_1
I0210 15:53:26.043581 27601 net.cpp:141] Setting up relu4_1
I0210 15:53:26.043594 27601 net.cpp:148] Top shape: 16 512 28 28 (6422528)
I0210 15:53:26.043597 27601 net.cpp:156] Memory required for data: 1692336320
I0210 15:53:26.043601 27601 layer_factory.hpp:77] Creating layer conv4_2
I0210 15:53:26.043611 27601 net.cpp:91] Creating Layer conv4_2
I0210 15:53:26.043615 27601 net.cpp:425] conv4_2 <- relu4_1
I0210 15:53:26.043622 27601 net.cpp:399] conv4_2 -> conv4_2
I0210 15:53:26.050222 27601 net.cpp:141] Setting up conv4_2
I0210 15:53:26.050238 27601 net.cpp:148] Top shape: 16 512 28 28 (6422528)
I0210 15:53:26.050254 27601 net.cpp:156] Memory required for data: 1718026432
I0210 15:53:26.050264 27601 layer_factory.hpp:77] Creating layer relu4_2
I0210 15:53:26.050271 27601 net.cpp:91] Creating Layer relu4_2
I0210 15:53:26.050274 27601 net.cpp:425] relu4_2 <- conv4_2
I0210 15:53:26.050282 27601 net.cpp:399] relu4_2 -> relu4_2
I0210 15:53:26.050457 27601 net.cpp:141] Setting up relu4_2
I0210 15:53:26.050467 27601 net.cpp:148] Top shape: 16 512 28 28 (6422528)
I0210 15:53:26.050469 27601 net.cpp:156] Memory required for data: 1743716544
I0210 15:53:26.050473 27601 layer_factory.hpp:77] Creating layer conv4_3
I0210 15:53:26.050485 27601 net.cpp:91] Creating Layer conv4_3
I0210 15:53:26.050489 27601 net.cpp:425] conv4_3 <- relu4_2
I0210 15:53:26.050495 27601 net.cpp:399] conv4_3 -> conv4_3
I0210 15:53:26.057385 27601 net.cpp:141] Setting up conv4_3
I0210 15:53:26.057422 27601 net.cpp:148] Top shape: 16 512 28 28 (6422528)
I0210 15:53:26.057427 27601 net.cpp:156] Memory required for data: 1769406656
I0210 15:53:26.057435 27601 layer_factory.hpp:77] Creating layer relu4_3
I0210 15:53:26.057442 27601 net.cpp:91] Creating Layer relu4_3
I0210 15:53:26.057446 27601 net.cpp:425] relu4_3 <- conv4_3
I0210 15:53:26.057452 27601 net.cpp:399] relu4_3 -> relu4_3
I0210 15:53:26.057636 27601 net.cpp:141] Setting up relu4_3
I0210 15:53:26.057646 27601 net.cpp:148] Top shape: 16 512 28 28 (6422528)
I0210 15:53:26.057649 27601 net.cpp:156] Memory required for data: 1795096768
I0210 15:53:26.057652 27601 layer_factory.hpp:77] Creating layer pool4
I0210 15:53:26.057659 27601 net.cpp:91] Creating Layer pool4
I0210 15:53:26.057663 27601 net.cpp:425] pool4 <- relu4_3
I0210 15:53:26.057670 27601 net.cpp:399] pool4 -> pool4
I0210 15:53:26.057711 27601 net.cpp:141] Setting up pool4
I0210 15:53:26.057718 27601 net.cpp:148] Top shape: 16 512 14 14 (1605632)
I0210 15:53:26.057721 27601 net.cpp:156] Memory required for data: 1801519296
I0210 15:53:26.057724 27601 layer_factory.hpp:77] Creating layer conv5_1
I0210 15:53:26.057736 27601 net.cpp:91] Creating Layer conv5_1
I0210 15:53:26.057740 27601 net.cpp:425] conv5_1 <- pool4
I0210 15:53:26.057746 27601 net.cpp:399] conv5_1 -> conv5_1
I0210 15:53:26.064699 27601 net.cpp:141] Setting up conv5_1
I0210 15:53:26.064718 27601 net.cpp:148] Top shape: 16 512 14 14 (1605632)
I0210 15:53:26.064723 27601 net.cpp:156] Memory required for data: 1807941824
I0210 15:53:26.064730 27601 layer_factory.hpp:77] Creating layer relu5_1
I0210 15:53:26.064736 27601 net.cpp:91] Creating Layer relu5_1
I0210 15:53:26.064740 27601 net.cpp:425] relu5_1 <- conv5_1
I0210 15:53:26.064749 27601 net.cpp:399] relu5_1 -> relu5_1
I0210 15:53:26.065122 27601 net.cpp:141] Setting up relu5_1
I0210 15:53:26.065135 27601 net.cpp:148] Top shape: 16 512 14 14 (1605632)
I0210 15:53:26.065153 27601 net.cpp:156] Memory required for data: 1814364352
I0210 15:53:26.065178 27601 layer_factory.hpp:77] Creating layer conv5_2
I0210 15:53:26.065192 27601 net.cpp:91] Creating Layer conv5_2
I0210 15:53:26.065197 27601 net.cpp:425] conv5_2 <- relu5_1
I0210 15:53:26.065214 27601 net.cpp:399] conv5_2 -> conv5_2
I0210 15:53:26.072329 27601 net.cpp:141] Setting up conv5_2
I0210 15:53:26.072360 27601 net.cpp:148] Top shape: 16 512 14 14 (1605632)
I0210 15:53:26.072365 27601 net.cpp:156] Memory required for data: 1820786880
I0210 15:53:26.072371 27601 layer_factory.hpp:77] Creating layer relu5_2
I0210 15:53:26.072377 27601 net.cpp:91] Creating Layer relu5_2
I0210 15:53:26.072381 27601 net.cpp:425] relu5_2 <- conv5_2
I0210 15:53:26.072386 27601 net.cpp:399] relu5_2 -> relu5_2
I0210 15:53:26.072566 27601 net.cpp:141] Setting up relu5_2
I0210 15:53:26.072577 27601 net.cpp:148] Top shape: 16 512 14 14 (1605632)
I0210 15:53:26.072582 27601 net.cpp:156] Memory required for data: 1827209408
I0210 15:53:26.072584 27601 layer_factory.hpp:77] Creating layer conv5_3
I0210 15:53:26.072594 27601 net.cpp:91] Creating Layer conv5_3
I0210 15:53:26.072598 27601 net.cpp:425] conv5_3 <- relu5_2
I0210 15:53:26.072605 27601 net.cpp:399] conv5_3 -> conv5_3
I0210 15:53:26.081342 27601 net.cpp:141] Setting up conv5_3
I0210 15:53:26.081359 27601 net.cpp:148] Top shape: 16 512 14 14 (1605632)
I0210 15:53:26.081375 27601 net.cpp:156] Memory required for data: 1833631936
I0210 15:53:26.081382 27601 layer_factory.hpp:77] Creating layer relu5_3
I0210 15:53:26.081389 27601 net.cpp:91] Creating Layer relu5_3
I0210 15:53:26.081393 27601 net.cpp:425] relu5_3 <- conv5_3
I0210 15:53:26.081398 27601 net.cpp:399] relu5_3 -> relu5_3
I0210 15:53:26.081586 27601 net.cpp:141] Setting up relu5_3
I0210 15:53:26.081598 27601 net.cpp:148] Top shape: 16 512 14 14 (1605632)
I0210 15:53:26.081604 27601 net.cpp:156] Memory required for data: 1840054464
I0210 15:53:26.081606 27601 layer_factory.hpp:77] Creating layer pool5
I0210 15:53:26.081621 27601 net.cpp:91] Creating Layer pool5
I0210 15:53:26.081625 27601 net.cpp:425] pool5 <- relu5_3
I0210 15:53:26.081631 27601 net.cpp:399] pool5 -> pool5
I0210 15:53:26.082013 27601 net.cpp:141] Setting up pool5
I0210 15:53:26.082027 27601 net.cpp:148] Top shape: 16 512 1 1 (8192)
I0210 15:53:26.082031 27601 net.cpp:156] Memory required for data: 1840087232
I0210 15:53:26.082034 27601 layer_factory.hpp:77] Creating layer softmax
I0210 15:53:26.082046 27601 net.cpp:91] Creating Layer softmax
I0210 15:53:26.082053 27601 net.cpp:425] softmax <- pool5
I0210 15:53:26.082059 27601 net.cpp:399] softmax -> softmax
I0210 15:53:26.095492 27601 net.cpp:141] Setting up softmax
I0210 15:53:26.095521 27601 net.cpp:148] Top shape: 16 200 1 1 (3200)
I0210 15:53:26.095526 27601 net.cpp:156] Memory required for data: 1840100032
I0210 15:53:26.095533 27601 layer_factory.hpp:77] Creating layer softmax_softmax_0_split
I0210 15:53:26.095543 27601 net.cpp:91] Creating Layer softmax_softmax_0_split
I0210 15:53:26.095547 27601 net.cpp:425] softmax_softmax_0_split <- softmax
I0210 15:53:26.095553 27601 net.cpp:399] softmax_softmax_0_split -> softmax_softmax_0_split_0
I0210 15:53:26.095561 27601 net.cpp:399] softmax_softmax_0_split -> softmax_softmax_0_split_1
I0210 15:53:26.095610 27601 net.cpp:141] Setting up softmax_softmax_0_split
I0210 15:53:26.095618 27601 net.cpp:148] Top shape: 16 200 1 1 (3200)
I0210 15:53:26.095623 27601 net.cpp:148] Top shape: 16 200 1 1 (3200)
I0210 15:53:26.095625 27601 net.cpp:156] Memory required for data: 1840125632
I0210 15:53:26.095628 27601 layer_factory.hpp:77] Creating layer loss
I0210 15:53:26.095634 27601 net.cpp:91] Creating Layer loss
I0210 15:53:26.095638 27601 net.cpp:425] loss <- softmax_softmax_0_split_0
I0210 15:53:26.095643 27601 net.cpp:425] loss <- label_data_1_split_0
I0210 15:53:26.095649 27601 net.cpp:399] loss -> loss
I0210 15:53:26.095662 27601 layer_factory.hpp:77] Creating layer loss
I0210 15:53:26.095959 27601 net.cpp:141] Setting up loss
I0210 15:53:26.095973 27601 net.cpp:148] Top shape: (1)
I0210 15:53:26.095976 27601 net.cpp:151]     with loss weight 1
I0210 15:53:26.096031 27601 net.cpp:156] Memory required for data: 1840125636
I0210 15:53:26.096036 27601 layer_factory.hpp:77] Creating layer acc_top_1
I0210 15:53:26.096043 27601 net.cpp:91] Creating Layer acc_top_1
I0210 15:53:26.096047 27601 net.cpp:425] acc_top_1 <- softmax_softmax_0_split_1
I0210 15:53:26.096052 27601 net.cpp:425] acc_top_1 <- label_data_1_split_1
I0210 15:53:26.096057 27601 net.cpp:399] acc_top_1 -> acc_top_1
I0210 15:53:26.096071 27601 net.cpp:141] Setting up acc_top_1
I0210 15:53:26.096081 27601 net.cpp:148] Top shape: (1)
I0210 15:53:26.096083 27601 net.cpp:156] Memory required for data: 1840125640
I0210 15:53:26.096087 27601 net.cpp:219] acc_top_1 does not need backward computation.
I0210 15:53:26.096091 27601 net.cpp:217] loss needs backward computation.
I0210 15:53:26.096094 27601 net.cpp:217] softmax_softmax_0_split needs backward computation.
I0210 15:53:26.096097 27601 net.cpp:217] softmax needs backward computation.
I0210 15:53:26.096101 27601 net.cpp:217] pool5 needs backward computation.
I0210 15:53:26.096103 27601 net.cpp:217] relu5_3 needs backward computation.
I0210 15:53:26.096107 27601 net.cpp:217] conv5_3 needs backward computation.
I0210 15:53:26.096110 27601 net.cpp:217] relu5_2 needs backward computation.
I0210 15:53:26.096114 27601 net.cpp:217] conv5_2 needs backward computation.
I0210 15:53:26.096117 27601 net.cpp:217] relu5_1 needs backward computation.
I0210 15:53:26.096120 27601 net.cpp:217] conv5_1 needs backward computation.
I0210 15:53:26.096123 27601 net.cpp:217] pool4 needs backward computation.
I0210 15:53:26.096127 27601 net.cpp:217] relu4_3 needs backward computation.
I0210 15:53:26.096130 27601 net.cpp:217] conv4_3 needs backward computation.
I0210 15:53:26.096135 27601 net.cpp:217] relu4_2 needs backward computation.
I0210 15:53:26.096139 27601 net.cpp:217] conv4_2 needs backward computation.
I0210 15:53:26.096143 27601 net.cpp:217] relu4_1 needs backward computation.
I0210 15:53:26.096156 27601 net.cpp:217] conv4_1 needs backward computation.
I0210 15:53:26.096160 27601 net.cpp:217] pool3 needs backward computation.
I0210 15:53:26.096163 27601 net.cpp:217] relu3_3 needs backward computation.
I0210 15:53:26.096168 27601 net.cpp:217] conv3_3 needs backward computation.
I0210 15:53:26.096170 27601 net.cpp:217] relu3_2 needs backward computation.
I0210 15:53:26.096174 27601 net.cpp:217] conv3_2 needs backward computation.
I0210 15:53:26.096177 27601 net.cpp:217] relu3_1 needs backward computation.
I0210 15:53:26.096180 27601 net.cpp:217] conv3_1 needs backward computation.
I0210 15:53:26.096184 27601 net.cpp:217] pool2 needs backward computation.
I0210 15:53:26.096186 27601 net.cpp:217] relu2_2 needs backward computation.
I0210 15:53:26.096190 27601 net.cpp:217] conv2_2 needs backward computation.
I0210 15:53:26.096194 27601 net.cpp:217] relu2_1 needs backward computation.
I0210 15:53:26.096197 27601 net.cpp:217] conv2_1 needs backward computation.
I0210 15:53:26.096200 27601 net.cpp:217] pool1 needs backward computation.
I0210 15:53:26.096204 27601 net.cpp:217] relu1_2 needs backward computation.
I0210 15:53:26.096207 27601 net.cpp:217] conv1_2 needs backward computation.
I0210 15:53:26.096211 27601 net.cpp:217] relu1_1 needs backward computation.
I0210 15:53:26.096215 27601 net.cpp:217] conv1_1 needs backward computation.
I0210 15:53:26.096218 27601 net.cpp:219] label_data_1_split does not need backward computation.
I0210 15:53:26.096222 27601 net.cpp:219] data does not need backward computation.
I0210 15:53:26.096225 27601 net.cpp:261] This network produces output acc_top_1
I0210 15:53:26.096228 27601 net.cpp:261] This network produces output loss
I0210 15:53:26.096261 27601 net.cpp:274] Network initialization done.
I0210 15:53:26.096940 27601 solver.cpp:181] Creating test net (#0) specified by net file: /opt/luojh/Net-Compression/value_sum/CUB200/1_ft_avg_vgg/avg_vgg/trainval.prototxt
I0210 15:53:26.096987 27601 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0210 15:53:26.097252 27601 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 224
    mean_value: 110
    mean_value: 127
    mean_value: 123
  }
  data_param {
    source: "/opt/luojh/Dataset/CUB/LMDB/cub200_2011_val_lmdb"
    batch_size: 2
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "relu1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "relu1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "relu1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "relu2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "relu2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "relu2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "relu3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "relu3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "relu3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "relu3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "relu3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "relu3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "relu4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "relu4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "relu4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "relu4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "relu4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "relu4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "relu5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "relu5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "relu5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "relu5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "relu5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5_3"
  top: "pool5"
  pooling_param {
    pool: AVE
    kernel_size: 14
    stride: 1
  }
}
layer {
  name: "softmax"
  type: "Convolution"
  bottom: "pool5"
  top: "softmax"
  param {
    lr_mult: 10
    decay_mult: 10
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  convolution_param {
    num_output: 200
    kernel_size: 1
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "softmax"
  bottom: "label"
  top: "loss"
}
layer {
  name: "acc_top_1"
  type: "Accuracy"
  bottom: "softmax"
  bottom: "label"
  top: "acc_top_1"
  accuracy_param {
    top_k: 1
  }
}
I0210 15:53:26.097396 27601 layer_factory.hpp:77] Creating layer data
I0210 15:53:26.097470 27601 net.cpp:91] Creating Layer data
I0210 15:53:26.097478 27601 net.cpp:399] data -> data
I0210 15:53:26.097488 27601 net.cpp:399] data -> label
I0210 15:53:26.124032 27608 db_lmdb.cpp:35] Opened lmdb /opt/luojh/Dataset/CUB/LMDB/cub200_2011_val_lmdb
I0210 15:53:26.144698 27601 data_layer.cpp:41] output data size: 2,3,224,224
I0210 15:53:26.152138 27601 net.cpp:141] Setting up data
I0210 15:53:26.152178 27601 net.cpp:148] Top shape: 2 3 224 224 (301056)
I0210 15:53:26.152199 27601 net.cpp:148] Top shape: 2 (2)
I0210 15:53:26.152207 27601 net.cpp:156] Memory required for data: 1204232
I0210 15:53:26.152220 27601 layer_factory.hpp:77] Creating layer label_data_1_split
I0210 15:53:26.152240 27601 net.cpp:91] Creating Layer label_data_1_split
I0210 15:53:26.152248 27601 net.cpp:425] label_data_1_split <- label
I0210 15:53:26.152262 27601 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0210 15:53:26.152282 27601 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0210 15:53:26.152516 27601 net.cpp:141] Setting up label_data_1_split
I0210 15:53:26.152536 27601 net.cpp:148] Top shape: 2 (2)
I0210 15:53:26.152546 27601 net.cpp:148] Top shape: 2 (2)
I0210 15:53:26.152554 27601 net.cpp:156] Memory required for data: 1204248
I0210 15:53:26.152562 27601 layer_factory.hpp:77] Creating layer conv1_1
I0210 15:53:26.152591 27601 net.cpp:91] Creating Layer conv1_1
I0210 15:53:26.152601 27601 net.cpp:425] conv1_1 <- data
I0210 15:53:26.152618 27601 net.cpp:399] conv1_1 -> conv1_1
I0210 15:53:26.154917 27601 net.cpp:141] Setting up conv1_1
I0210 15:53:26.154942 27601 net.cpp:148] Top shape: 2 64 224 224 (6422528)
I0210 15:53:26.154947 27601 net.cpp:156] Memory required for data: 26894360
I0210 15:53:26.154958 27601 layer_factory.hpp:77] Creating layer relu1_1
I0210 15:53:26.154964 27601 net.cpp:91] Creating Layer relu1_1
I0210 15:53:26.154968 27601 net.cpp:425] relu1_1 <- conv1_1
I0210 15:53:26.154974 27601 net.cpp:399] relu1_1 -> relu1_1
I0210 15:53:26.155618 27601 net.cpp:141] Setting up relu1_1
I0210 15:53:26.155642 27601 net.cpp:148] Top shape: 2 64 224 224 (6422528)
I0210 15:53:26.155663 27601 net.cpp:156] Memory required for data: 52584472
I0210 15:53:26.155668 27601 layer_factory.hpp:77] Creating layer conv1_2
I0210 15:53:26.155678 27601 net.cpp:91] Creating Layer conv1_2
I0210 15:53:26.155683 27601 net.cpp:425] conv1_2 <- relu1_1
I0210 15:53:26.155690 27601 net.cpp:399] conv1_2 -> conv1_2
I0210 15:53:26.157444 27601 net.cpp:141] Setting up conv1_2
I0210 15:53:26.157459 27601 net.cpp:148] Top shape: 2 64 224 224 (6422528)
I0210 15:53:26.157464 27601 net.cpp:156] Memory required for data: 78274584
I0210 15:53:26.157472 27601 layer_factory.hpp:77] Creating layer relu1_2
I0210 15:53:26.157480 27601 net.cpp:91] Creating Layer relu1_2
I0210 15:53:26.157482 27601 net.cpp:425] relu1_2 <- conv1_2
I0210 15:53:26.157492 27601 net.cpp:399] relu1_2 -> relu1_2
I0210 15:53:26.158192 27601 net.cpp:141] Setting up relu1_2
I0210 15:53:26.158206 27601 net.cpp:148] Top shape: 2 64 224 224 (6422528)
I0210 15:53:26.158210 27601 net.cpp:156] Memory required for data: 103964696
I0210 15:53:26.158213 27601 layer_factory.hpp:77] Creating layer pool1
I0210 15:53:26.158222 27601 net.cpp:91] Creating Layer pool1
I0210 15:53:26.158226 27601 net.cpp:425] pool1 <- relu1_2
I0210 15:53:26.158231 27601 net.cpp:399] pool1 -> pool1
I0210 15:53:26.158277 27601 net.cpp:141] Setting up pool1
I0210 15:53:26.158287 27601 net.cpp:148] Top shape: 2 64 112 112 (1605632)
I0210 15:53:26.158289 27601 net.cpp:156] Memory required for data: 110387224
I0210 15:53:26.158293 27601 layer_factory.hpp:77] Creating layer conv2_1
I0210 15:53:26.158299 27601 net.cpp:91] Creating Layer conv2_1
I0210 15:53:26.158303 27601 net.cpp:425] conv2_1 <- pool1
I0210 15:53:26.158308 27601 net.cpp:399] conv2_1 -> conv2_1
I0210 15:53:26.159580 27601 net.cpp:141] Setting up conv2_1
I0210 15:53:26.159605 27601 net.cpp:148] Top shape: 2 128 112 112 (3211264)
I0210 15:53:26.159608 27601 net.cpp:156] Memory required for data: 123232280
I0210 15:53:26.159618 27601 layer_factory.hpp:77] Creating layer relu2_1
I0210 15:53:26.159627 27601 net.cpp:91] Creating Layer relu2_1
I0210 15:53:26.159631 27601 net.cpp:425] relu2_1 <- conv2_1
I0210 15:53:26.159636 27601 net.cpp:399] relu2_1 -> relu2_1
I0210 15:53:26.159821 27601 net.cpp:141] Setting up relu2_1
I0210 15:53:26.159832 27601 net.cpp:148] Top shape: 2 128 112 112 (3211264)
I0210 15:53:26.159834 27601 net.cpp:156] Memory required for data: 136077336
I0210 15:53:26.159838 27601 layer_factory.hpp:77] Creating layer conv2_2
I0210 15:53:26.159847 27601 net.cpp:91] Creating Layer conv2_2
I0210 15:53:26.159852 27601 net.cpp:425] conv2_2 <- relu2_1
I0210 15:53:26.159857 27601 net.cpp:399] conv2_2 -> conv2_2
I0210 15:53:26.162292 27601 net.cpp:141] Setting up conv2_2
I0210 15:53:26.162317 27601 net.cpp:148] Top shape: 2 128 112 112 (3211264)
I0210 15:53:26.162320 27601 net.cpp:156] Memory required for data: 148922392
I0210 15:53:26.162327 27601 layer_factory.hpp:77] Creating layer relu2_2
I0210 15:53:26.162333 27601 net.cpp:91] Creating Layer relu2_2
I0210 15:53:26.162336 27601 net.cpp:425] relu2_2 <- conv2_2
I0210 15:53:26.162343 27601 net.cpp:399] relu2_2 -> relu2_2
I0210 15:53:26.162715 27601 net.cpp:141] Setting up relu2_2
I0210 15:53:26.162729 27601 net.cpp:148] Top shape: 2 128 112 112 (3211264)
I0210 15:53:26.162741 27601 net.cpp:156] Memory required for data: 161767448
I0210 15:53:26.162745 27601 layer_factory.hpp:77] Creating layer pool2
I0210 15:53:26.162762 27601 net.cpp:91] Creating Layer pool2
I0210 15:53:26.162765 27601 net.cpp:425] pool2 <- relu2_2
I0210 15:53:26.162773 27601 net.cpp:399] pool2 -> pool2
I0210 15:53:26.162819 27601 net.cpp:141] Setting up pool2
I0210 15:53:26.162827 27601 net.cpp:148] Top shape: 2 128 56 56 (802816)
I0210 15:53:26.162830 27601 net.cpp:156] Memory required for data: 164978712
I0210 15:53:26.162833 27601 layer_factory.hpp:77] Creating layer conv3_1
I0210 15:53:26.162842 27601 net.cpp:91] Creating Layer conv3_1
I0210 15:53:26.162845 27601 net.cpp:425] conv3_1 <- pool2
I0210 15:53:26.162850 27601 net.cpp:399] conv3_1 -> conv3_1
I0210 15:53:26.165102 27601 net.cpp:141] Setting up conv3_1
I0210 15:53:26.165130 27601 net.cpp:148] Top shape: 2 256 56 56 (1605632)
I0210 15:53:26.165134 27601 net.cpp:156] Memory required for data: 171401240
I0210 15:53:26.165155 27601 layer_factory.hpp:77] Creating layer relu3_1
I0210 15:53:26.165163 27601 net.cpp:91] Creating Layer relu3_1
I0210 15:53:26.165168 27601 net.cpp:425] relu3_1 <- conv3_1
I0210 15:53:26.165172 27601 net.cpp:399] relu3_1 -> relu3_1
I0210 15:53:26.165835 27601 net.cpp:141] Setting up relu3_1
I0210 15:53:26.165849 27601 net.cpp:148] Top shape: 2 256 56 56 (1605632)
I0210 15:53:26.165853 27601 net.cpp:156] Memory required for data: 177823768
I0210 15:53:26.165858 27601 layer_factory.hpp:77] Creating layer conv3_2
I0210 15:53:26.165866 27601 net.cpp:91] Creating Layer conv3_2
I0210 15:53:26.165870 27601 net.cpp:425] conv3_2 <- relu3_1
I0210 15:53:26.165879 27601 net.cpp:399] conv3_2 -> conv3_2
I0210 15:53:26.169083 27601 net.cpp:141] Setting up conv3_2
I0210 15:53:26.169112 27601 net.cpp:148] Top shape: 2 256 56 56 (1605632)
I0210 15:53:26.169116 27601 net.cpp:156] Memory required for data: 184246296
I0210 15:53:26.169122 27601 layer_factory.hpp:77] Creating layer relu3_2
I0210 15:53:26.169131 27601 net.cpp:91] Creating Layer relu3_2
I0210 15:53:26.169137 27601 net.cpp:425] relu3_2 <- conv3_2
I0210 15:53:26.169142 27601 net.cpp:399] relu3_2 -> relu3_2
I0210 15:53:26.169337 27601 net.cpp:141] Setting up relu3_2
I0210 15:53:26.169348 27601 net.cpp:148] Top shape: 2 256 56 56 (1605632)
I0210 15:53:26.169350 27601 net.cpp:156] Memory required for data: 190668824
I0210 15:53:26.169354 27601 layer_factory.hpp:77] Creating layer conv3_3
I0210 15:53:26.169366 27601 net.cpp:91] Creating Layer conv3_3
I0210 15:53:26.169371 27601 net.cpp:425] conv3_3 <- relu3_2
I0210 15:53:26.169378 27601 net.cpp:399] conv3_3 -> conv3_3
I0210 15:53:26.173832 27601 net.cpp:141] Setting up conv3_3
I0210 15:53:26.173856 27601 net.cpp:148] Top shape: 2 256 56 56 (1605632)
I0210 15:53:26.173863 27601 net.cpp:156] Memory required for data: 197091352
I0210 15:53:26.173869 27601 layer_factory.hpp:77] Creating layer relu3_3
I0210 15:53:26.173876 27601 net.cpp:91] Creating Layer relu3_3
I0210 15:53:26.173879 27601 net.cpp:425] relu3_3 <- conv3_3
I0210 15:53:26.173887 27601 net.cpp:399] relu3_3 -> relu3_3
I0210 15:53:26.174245 27601 net.cpp:141] Setting up relu3_3
I0210 15:53:26.174258 27601 net.cpp:148] Top shape: 2 256 56 56 (1605632)
I0210 15:53:26.174271 27601 net.cpp:156] Memory required for data: 203513880
I0210 15:53:26.174275 27601 layer_factory.hpp:77] Creating layer pool3
I0210 15:53:26.174284 27601 net.cpp:91] Creating Layer pool3
I0210 15:53:26.174288 27601 net.cpp:425] pool3 <- relu3_3
I0210 15:53:26.174293 27601 net.cpp:399] pool3 -> pool3
I0210 15:53:26.174341 27601 net.cpp:141] Setting up pool3
I0210 15:53:26.174350 27601 net.cpp:148] Top shape: 2 256 28 28 (401408)
I0210 15:53:26.174351 27601 net.cpp:156] Memory required for data: 205119512
I0210 15:53:26.174355 27601 layer_factory.hpp:77] Creating layer conv4_1
I0210 15:53:26.174363 27601 net.cpp:91] Creating Layer conv4_1
I0210 15:53:26.174368 27601 net.cpp:425] conv4_1 <- pool3
I0210 15:53:26.174373 27601 net.cpp:399] conv4_1 -> conv4_1
I0210 15:53:26.180953 27601 net.cpp:141] Setting up conv4_1
I0210 15:53:26.180968 27601 net.cpp:148] Top shape: 2 512 28 28 (802816)
I0210 15:53:26.180971 27601 net.cpp:156] Memory required for data: 208330776
I0210 15:53:26.180977 27601 layer_factory.hpp:77] Creating layer relu4_1
I0210 15:53:26.180985 27601 net.cpp:91] Creating Layer relu4_1
I0210 15:53:26.180989 27601 net.cpp:425] relu4_1 <- conv4_1
I0210 15:53:26.180994 27601 net.cpp:399] relu4_1 -> relu4_1
I0210 15:53:26.181354 27601 net.cpp:141] Setting up relu4_1
I0210 15:53:26.181367 27601 net.cpp:148] Top shape: 2 512 28 28 (802816)
I0210 15:53:26.181371 27601 net.cpp:156] Memory required for data: 211542040
I0210 15:53:26.181375 27601 layer_factory.hpp:77] Creating layer conv4_2
I0210 15:53:26.181385 27601 net.cpp:91] Creating Layer conv4_2
I0210 15:53:26.181391 27601 net.cpp:425] conv4_2 <- relu4_1
I0210 15:53:26.181411 27601 net.cpp:399] conv4_2 -> conv4_2
I0210 15:53:26.188777 27601 net.cpp:141] Setting up conv4_2
I0210 15:53:26.188802 27601 net.cpp:148] Top shape: 2 512 28 28 (802816)
I0210 15:53:26.188808 27601 net.cpp:156] Memory required for data: 214753304
I0210 15:53:26.188823 27601 layer_factory.hpp:77] Creating layer relu4_2
I0210 15:53:26.188834 27601 net.cpp:91] Creating Layer relu4_2
I0210 15:53:26.188840 27601 net.cpp:425] relu4_2 <- conv4_2
I0210 15:53:26.188849 27601 net.cpp:399] relu4_2 -> relu4_2
I0210 15:53:26.189079 27601 net.cpp:141] Setting up relu4_2
I0210 15:53:26.189091 27601 net.cpp:148] Top shape: 2 512 28 28 (802816)
I0210 15:53:26.189096 27601 net.cpp:156] Memory required for data: 217964568
I0210 15:53:26.189100 27601 layer_factory.hpp:77] Creating layer conv4_3
I0210 15:53:26.189112 27601 net.cpp:91] Creating Layer conv4_3
I0210 15:53:26.189118 27601 net.cpp:425] conv4_3 <- relu4_2
I0210 15:53:26.189127 27601 net.cpp:399] conv4_3 -> conv4_3
I0210 15:53:26.196439 27601 net.cpp:141] Setting up conv4_3
I0210 15:53:26.196456 27601 net.cpp:148] Top shape: 2 512 28 28 (802816)
I0210 15:53:26.196460 27601 net.cpp:156] Memory required for data: 221175832
I0210 15:53:26.196467 27601 layer_factory.hpp:77] Creating layer relu4_3
I0210 15:53:26.196477 27601 net.cpp:91] Creating Layer relu4_3
I0210 15:53:26.196481 27601 net.cpp:425] relu4_3 <- conv4_3
I0210 15:53:26.196487 27601 net.cpp:399] relu4_3 -> relu4_3
I0210 15:53:26.196851 27601 net.cpp:141] Setting up relu4_3
I0210 15:53:26.196864 27601 net.cpp:148] Top shape: 2 512 28 28 (802816)
I0210 15:53:26.196869 27601 net.cpp:156] Memory required for data: 224387096
I0210 15:53:26.196872 27601 layer_factory.hpp:77] Creating layer pool4
I0210 15:53:26.196882 27601 net.cpp:91] Creating Layer pool4
I0210 15:53:26.196887 27601 net.cpp:425] pool4 <- relu4_3
I0210 15:53:26.196892 27601 net.cpp:399] pool4 -> pool4
I0210 15:53:26.196955 27601 net.cpp:141] Setting up pool4
I0210 15:53:26.196964 27601 net.cpp:148] Top shape: 2 512 14 14 (200704)
I0210 15:53:26.196966 27601 net.cpp:156] Memory required for data: 225189912
I0210 15:53:26.196969 27601 layer_factory.hpp:77] Creating layer conv5_1
I0210 15:53:26.196979 27601 net.cpp:91] Creating Layer conv5_1
I0210 15:53:26.196983 27601 net.cpp:425] conv5_1 <- pool4
I0210 15:53:26.196990 27601 net.cpp:399] conv5_1 -> conv5_1
I0210 15:53:26.204207 27601 net.cpp:141] Setting up conv5_1
I0210 15:53:26.204234 27601 net.cpp:148] Top shape: 2 512 14 14 (200704)
I0210 15:53:26.204238 27601 net.cpp:156] Memory required for data: 225992728
I0210 15:53:26.204246 27601 layer_factory.hpp:77] Creating layer relu5_1
I0210 15:53:26.204252 27601 net.cpp:91] Creating Layer relu5_1
I0210 15:53:26.204255 27601 net.cpp:425] relu5_1 <- conv5_1
I0210 15:53:26.204262 27601 net.cpp:399] relu5_1 -> relu5_1
I0210 15:53:26.204629 27601 net.cpp:141] Setting up relu5_1
I0210 15:53:26.204643 27601 net.cpp:148] Top shape: 2 512 14 14 (200704)
I0210 15:53:26.204646 27601 net.cpp:156] Memory required for data: 226795544
I0210 15:53:26.204650 27601 layer_factory.hpp:77] Creating layer conv5_2
I0210 15:53:26.204660 27601 net.cpp:91] Creating Layer conv5_2
I0210 15:53:26.204665 27601 net.cpp:425] conv5_2 <- relu5_1
I0210 15:53:26.204673 27601 net.cpp:399] conv5_2 -> conv5_2
I0210 15:53:26.211935 27601 net.cpp:141] Setting up conv5_2
I0210 15:53:26.211967 27601 net.cpp:148] Top shape: 2 512 14 14 (200704)
I0210 15:53:26.211972 27601 net.cpp:156] Memory required for data: 227598360
I0210 15:53:26.211979 27601 layer_factory.hpp:77] Creating layer relu5_2
I0210 15:53:26.211987 27601 net.cpp:91] Creating Layer relu5_2
I0210 15:53:26.211990 27601 net.cpp:425] relu5_2 <- conv5_2
I0210 15:53:26.211997 27601 net.cpp:399] relu5_2 -> relu5_2
I0210 15:53:26.212209 27601 net.cpp:141] Setting up relu5_2
I0210 15:53:26.212219 27601 net.cpp:148] Top shape: 2 512 14 14 (200704)
I0210 15:53:26.212229 27601 net.cpp:156] Memory required for data: 228401176
I0210 15:53:26.212231 27601 layer_factory.hpp:77] Creating layer conv5_3
I0210 15:53:26.212239 27601 net.cpp:91] Creating Layer conv5_3
I0210 15:53:26.212261 27601 net.cpp:425] conv5_3 <- relu5_2
I0210 15:53:26.212270 27601 net.cpp:399] conv5_3 -> conv5_3
I0210 15:53:26.220413 27601 net.cpp:141] Setting up conv5_3
I0210 15:53:26.220456 27601 net.cpp:148] Top shape: 2 512 14 14 (200704)
I0210 15:53:26.220463 27601 net.cpp:156] Memory required for data: 229203992
I0210 15:53:26.220473 27601 layer_factory.hpp:77] Creating layer relu5_3
I0210 15:53:26.220481 27601 net.cpp:91] Creating Layer relu5_3
I0210 15:53:26.220487 27601 net.cpp:425] relu5_3 <- conv5_3
I0210 15:53:26.220497 27601 net.cpp:399] relu5_3 -> relu5_3
I0210 15:53:26.221002 27601 net.cpp:141] Setting up relu5_3
I0210 15:53:26.221019 27601 net.cpp:148] Top shape: 2 512 14 14 (200704)
I0210 15:53:26.221025 27601 net.cpp:156] Memory required for data: 230006808
I0210 15:53:26.221031 27601 layer_factory.hpp:77] Creating layer pool5
I0210 15:53:26.221048 27601 net.cpp:91] Creating Layer pool5
I0210 15:53:26.221055 27601 net.cpp:425] pool5 <- relu5_3
I0210 15:53:26.221065 27601 net.cpp:399] pool5 -> pool5
I0210 15:53:26.221336 27601 net.cpp:141] Setting up pool5
I0210 15:53:26.221351 27601 net.cpp:148] Top shape: 2 512 1 1 (1024)
I0210 15:53:26.221356 27601 net.cpp:156] Memory required for data: 230010904
I0210 15:53:26.221361 27601 layer_factory.hpp:77] Creating layer softmax
I0210 15:53:26.221374 27601 net.cpp:91] Creating Layer softmax
I0210 15:53:26.221381 27601 net.cpp:425] softmax <- pool5
I0210 15:53:26.221390 27601 net.cpp:399] softmax -> softmax
I0210 15:53:26.223090 27601 net.cpp:141] Setting up softmax
I0210 15:53:26.223110 27601 net.cpp:148] Top shape: 2 200 1 1 (400)
I0210 15:53:26.223116 27601 net.cpp:156] Memory required for data: 230012504
I0210 15:53:26.223125 27601 layer_factory.hpp:77] Creating layer softmax_softmax_0_split
I0210 15:53:26.223135 27601 net.cpp:91] Creating Layer softmax_softmax_0_split
I0210 15:53:26.223141 27601 net.cpp:425] softmax_softmax_0_split <- softmax
I0210 15:53:26.223152 27601 net.cpp:399] softmax_softmax_0_split -> softmax_softmax_0_split_0
I0210 15:53:26.223165 27601 net.cpp:399] softmax_softmax_0_split -> softmax_softmax_0_split_1
I0210 15:53:26.223232 27601 net.cpp:141] Setting up softmax_softmax_0_split
I0210 15:53:26.223247 27601 net.cpp:148] Top shape: 2 200 1 1 (400)
I0210 15:53:26.223255 27601 net.cpp:148] Top shape: 2 200 1 1 (400)
I0210 15:53:26.223259 27601 net.cpp:156] Memory required for data: 230015704
I0210 15:53:26.223264 27601 layer_factory.hpp:77] Creating layer loss
I0210 15:53:26.223273 27601 net.cpp:91] Creating Layer loss
I0210 15:53:26.223280 27601 net.cpp:425] loss <- softmax_softmax_0_split_0
I0210 15:53:26.223287 27601 net.cpp:425] loss <- label_data_1_split_0
I0210 15:53:26.223294 27601 net.cpp:399] loss -> loss
I0210 15:53:26.223309 27601 layer_factory.hpp:77] Creating layer loss
I0210 15:53:26.223942 27601 net.cpp:141] Setting up loss
I0210 15:53:26.223960 27601 net.cpp:148] Top shape: (1)
I0210 15:53:26.223969 27601 net.cpp:151]     with loss weight 1
I0210 15:53:26.223990 27601 net.cpp:156] Memory required for data: 230015708
I0210 15:53:26.223996 27601 layer_factory.hpp:77] Creating layer acc_top_1
I0210 15:53:26.224007 27601 net.cpp:91] Creating Layer acc_top_1
I0210 15:53:26.224014 27601 net.cpp:425] acc_top_1 <- softmax_softmax_0_split_1
I0210 15:53:26.224020 27601 net.cpp:425] acc_top_1 <- label_data_1_split_1
I0210 15:53:26.224028 27601 net.cpp:399] acc_top_1 -> acc_top_1
I0210 15:53:26.224045 27601 net.cpp:141] Setting up acc_top_1
I0210 15:53:26.224053 27601 net.cpp:148] Top shape: (1)
I0210 15:53:26.224058 27601 net.cpp:156] Memory required for data: 230015712
I0210 15:53:26.224063 27601 net.cpp:219] acc_top_1 does not need backward computation.
I0210 15:53:26.224069 27601 net.cpp:217] loss needs backward computation.
I0210 15:53:26.224074 27601 net.cpp:217] softmax_softmax_0_split needs backward computation.
I0210 15:53:26.224081 27601 net.cpp:217] softmax needs backward computation.
I0210 15:53:26.224086 27601 net.cpp:217] pool5 needs backward computation.
I0210 15:53:26.224109 27601 net.cpp:217] relu5_3 needs backward computation.
I0210 15:53:26.224115 27601 net.cpp:217] conv5_3 needs backward computation.
I0210 15:53:26.224120 27601 net.cpp:217] relu5_2 needs backward computation.
I0210 15:53:26.224125 27601 net.cpp:217] conv5_2 needs backward computation.
I0210 15:53:26.224129 27601 net.cpp:217] relu5_1 needs backward computation.
I0210 15:53:26.224134 27601 net.cpp:217] conv5_1 needs backward computation.
I0210 15:53:26.224139 27601 net.cpp:217] pool4 needs backward computation.
I0210 15:53:26.224144 27601 net.cpp:217] relu4_3 needs backward computation.
I0210 15:53:26.224149 27601 net.cpp:217] conv4_3 needs backward computation.
I0210 15:53:26.224154 27601 net.cpp:217] relu4_2 needs backward computation.
I0210 15:53:26.224159 27601 net.cpp:217] conv4_2 needs backward computation.
I0210 15:53:26.224165 27601 net.cpp:217] relu4_1 needs backward computation.
I0210 15:53:26.224170 27601 net.cpp:217] conv4_1 needs backward computation.
I0210 15:53:26.224177 27601 net.cpp:217] pool3 needs backward computation.
I0210 15:53:26.224184 27601 net.cpp:217] relu3_3 needs backward computation.
I0210 15:53:26.224189 27601 net.cpp:217] conv3_3 needs backward computation.
I0210 15:53:26.224194 27601 net.cpp:217] relu3_2 needs backward computation.
I0210 15:53:26.224197 27601 net.cpp:217] conv3_2 needs backward computation.
I0210 15:53:26.224202 27601 net.cpp:217] relu3_1 needs backward computation.
I0210 15:53:26.224208 27601 net.cpp:217] conv3_1 needs backward computation.
I0210 15:53:26.224213 27601 net.cpp:217] pool2 needs backward computation.
I0210 15:53:26.224220 27601 net.cpp:217] relu2_2 needs backward computation.
I0210 15:53:26.224225 27601 net.cpp:217] conv2_2 needs backward computation.
I0210 15:53:26.224231 27601 net.cpp:217] relu2_1 needs backward computation.
I0210 15:53:26.224236 27601 net.cpp:217] conv2_1 needs backward computation.
I0210 15:53:26.224241 27601 net.cpp:217] pool1 needs backward computation.
I0210 15:53:26.224246 27601 net.cpp:217] relu1_2 needs backward computation.
I0210 15:53:26.224252 27601 net.cpp:217] conv1_2 needs backward computation.
I0210 15:53:26.224256 27601 net.cpp:217] relu1_1 needs backward computation.
I0210 15:53:26.224261 27601 net.cpp:217] conv1_1 needs backward computation.
I0210 15:53:26.224267 27601 net.cpp:219] label_data_1_split does not need backward computation.
I0210 15:53:26.224273 27601 net.cpp:219] data does not need backward computation.
I0210 15:53:26.224277 27601 net.cpp:261] This network produces output acc_top_1
I0210 15:53:26.224282 27601 net.cpp:261] This network produces output loss
I0210 15:53:26.224323 27601 net.cpp:274] Network initialization done.
I0210 15:53:26.224473 27601 solver.cpp:60] Solver scaffolding done.
I0210 15:53:26.227030 27601 caffe.cpp:129] Finetuning from /data/luojh/net/caffe/fc_conv_VGG_ILSVRC_16_layers.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:537] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
Total size is: 536870912
warning_size is: 536870912
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553433871
I0210 15:53:30.752045 27601 net.cpp:752] Ignoring source layer fc6_conv
I0210 15:53:30.752084 27601 net.cpp:752] Ignoring source layer relu6
I0210 15:53:30.752094 27601 net.cpp:752] Ignoring source layer drop6
I0210 15:53:30.752097 27601 net.cpp:752] Ignoring source layer fc7_conv
I0210 15:53:30.752100 27601 net.cpp:752] Ignoring source layer relu7
I0210 15:53:30.752104 27601 net.cpp:752] Ignoring source layer drop7
I0210 15:53:30.752107 27601 net.cpp:752] Ignoring source layer fc8_conv
I0210 15:53:30.752110 27601 net.cpp:752] Ignoring source layer fc8_conv_fc8_conv_0_split
I0210 15:53:30.752115 27601 net.cpp:752] Ignoring source layer acc_top_5
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:537] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
Total size is: 536870912
warning_size is: 536870912
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553433871
I0210 15:53:31.766641 27601 net.cpp:752] Ignoring source layer fc6_conv
I0210 15:53:31.766674 27601 net.cpp:752] Ignoring source layer relu6
I0210 15:53:31.766688 27601 net.cpp:752] Ignoring source layer drop6
I0210 15:53:31.766692 27601 net.cpp:752] Ignoring source layer fc7_conv
I0210 15:53:31.766695 27601 net.cpp:752] Ignoring source layer relu7
I0210 15:53:31.766697 27601 net.cpp:752] Ignoring source layer drop7
I0210 15:53:31.766700 27601 net.cpp:752] Ignoring source layer fc8_conv
I0210 15:53:31.766703 27601 net.cpp:752] Ignoring source layer fc8_conv_fc8_conv_0_split
I0210 15:53:31.766732 27601 net.cpp:752] Ignoring source layer acc_top_5
I0210 15:53:31.782196 27601 parallel.cpp:392] GPUs pairs 6:7
I0210 15:53:32.167489 27601 data_layer.cpp:41] output data size: 16,3,224,224
I0210 15:53:32.877609 27601 parallel.cpp:425] Starting Optimization
I0210 15:53:32.877712 27601 solver.cpp:279] Solving 
I0210 15:53:32.877720 27601 solver.cpp:280] Learning Rate Policy: multistep
I0210 15:53:33.324188 27601 solver.cpp:228] Iteration 0, loss = 5.29832
I0210 15:53:33.324226 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0
I0210 15:53:33.324236 27601 solver.cpp:244]     Train net output #1: loss = 5.29832 (* 1 = 5.29832 loss)
I0210 15:53:34.006304 27601 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0210 15:53:56.798739 27601 solver.cpp:228] Iteration 20, loss = 5.13871
I0210 15:53:56.798970 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.125
I0210 15:53:56.798986 27601 solver.cpp:244]     Train net output #1: loss = 5.13871 (* 1 = 5.13871 loss)
I0210 15:53:56.799021 27601 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0210 15:54:19.304105 27601 solver.cpp:228] Iteration 40, loss = 4.95993
I0210 15:54:19.304147 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0
I0210 15:54:19.304158 27601 solver.cpp:244]     Train net output #1: loss = 4.95993 (* 1 = 4.95993 loss)
I0210 15:54:20.147063 27601 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0210 15:54:42.817829 27601 solver.cpp:228] Iteration 60, loss = 4.32964
I0210 15:54:42.824285 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.0625
I0210 15:54:42.824304 27601 solver.cpp:244]     Train net output #1: loss = 4.32964 (* 1 = 4.32964 loss)
I0210 15:54:43.645712 27601 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0210 15:55:05.710319 27601 solver.cpp:228] Iteration 80, loss = 3.57799
I0210 15:55:05.710376 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.3125
I0210 15:55:05.710392 27601 solver.cpp:244]     Train net output #1: loss = 3.57799 (* 1 = 3.57799 loss)
I0210 15:55:06.537273 27601 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0210 15:55:29.358559 27601 solver.cpp:228] Iteration 100, loss = 3.50217
I0210 15:55:29.358901 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.1875
I0210 15:55:29.358919 27601 solver.cpp:244]     Train net output #1: loss = 3.50217 (* 1 = 3.50217 loss)
I0210 15:55:30.177870 27601 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0210 15:55:52.359591 27601 solver.cpp:228] Iteration 120, loss = 3.22588
I0210 15:55:52.359628 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.25
I0210 15:55:52.359640 27601 solver.cpp:244]     Train net output #1: loss = 3.22588 (* 1 = 3.22588 loss)
I0210 15:55:53.202867 27601 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0210 15:56:15.459391 27601 solver.cpp:228] Iteration 140, loss = 3.08065
I0210 15:56:15.459723 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.375
I0210 15:56:15.459741 27601 solver.cpp:244]     Train net output #1: loss = 3.08065 (* 1 = 3.08065 loss)
I0210 15:56:16.294795 27601 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0210 15:56:38.496410 27601 solver.cpp:228] Iteration 160, loss = 2.44683
I0210 15:56:38.496445 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.375
I0210 15:56:38.496456 27601 solver.cpp:244]     Train net output #1: loss = 2.44683 (* 1 = 2.44683 loss)
I0210 15:56:39.344612 27601 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0210 15:57:01.624775 27601 solver.cpp:228] Iteration 180, loss = 2.60236
I0210 15:57:01.625185 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.4375
I0210 15:57:01.625222 27601 solver.cpp:244]     Train net output #1: loss = 2.60236 (* 1 = 2.60236 loss)
I0210 15:57:02.463063 27601 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0210 15:57:10.558333 27601 solver.cpp:337] Iteration 188, Testing net (#0)
I0210 15:59:22.719689 27601 solver.cpp:404]     Test net output #0: acc_top_1 = 0.42941
I0210 15:59:22.735059 27601 solver.cpp:404]     Test net output #1: loss = 2.24176 (* 1 = 2.24176 loss)
I0210 15:59:36.736302 27601 solver.cpp:228] Iteration 200, loss = 2.43896
I0210 15:59:36.736335 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.25
I0210 15:59:36.736347 27601 solver.cpp:244]     Train net output #1: loss = 2.43896 (* 1 = 2.43896 loss)
I0210 15:59:37.575533 27601 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0210 15:59:59.638052 27601 solver.cpp:228] Iteration 220, loss = 1.46396
I0210 15:59:59.638577 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.5625
I0210 15:59:59.638630 27601 solver.cpp:244]     Train net output #1: loss = 1.46396 (* 1 = 1.46396 loss)
I0210 16:00:00.475445 27601 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0210 16:00:22.593842 27601 solver.cpp:228] Iteration 240, loss = 1.83318
I0210 16:00:22.593886 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.375
I0210 16:00:22.593899 27601 solver.cpp:244]     Train net output #1: loss = 1.83318 (* 1 = 1.83318 loss)
I0210 16:00:23.423442 27601 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0210 16:00:45.641645 27601 solver.cpp:228] Iteration 260, loss = 1.61332
I0210 16:00:45.642112 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.5625
I0210 16:00:45.642164 27601 solver.cpp:244]     Train net output #1: loss = 1.61332 (* 1 = 1.61332 loss)
I0210 16:00:46.496000 27601 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0210 16:01:08.761838 27601 solver.cpp:228] Iteration 280, loss = 1.46683
I0210 16:01:08.761871 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.5625
I0210 16:01:08.761883 27601 solver.cpp:244]     Train net output #1: loss = 1.46683 (* 1 = 1.46683 loss)
I0210 16:01:09.598582 27601 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0210 16:01:31.864694 27601 solver.cpp:228] Iteration 300, loss = 1.15546
I0210 16:01:31.865187 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.6875
I0210 16:01:31.865283 27601 solver.cpp:244]     Train net output #1: loss = 1.15546 (* 1 = 1.15546 loss)
I0210 16:01:32.701571 27601 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0210 16:01:54.989317 27601 solver.cpp:228] Iteration 320, loss = 1.89516
I0210 16:01:54.989353 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.5625
I0210 16:01:54.989365 27601 solver.cpp:244]     Train net output #1: loss = 1.89516 (* 1 = 1.89516 loss)
I0210 16:01:55.841111 27601 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0210 16:02:18.164542 27601 solver.cpp:228] Iteration 340, loss = 0.911875
I0210 16:02:18.166396 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.75
I0210 16:02:18.166416 27601 solver.cpp:244]     Train net output #1: loss = 0.911875 (* 1 = 0.911875 loss)
I0210 16:02:18.994086 27601 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0210 16:02:41.249857 27601 solver.cpp:228] Iteration 360, loss = 1.73766
I0210 16:02:41.249898 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.625
I0210 16:02:41.249910 27601 solver.cpp:244]     Train net output #1: loss = 1.73766 (* 1 = 1.73766 loss)
I0210 16:02:42.082607 27601 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0210 16:02:59.410912 27601 solver.cpp:337] Iteration 376, Testing net (#0)
I0210 16:05:11.176563 27601 solver.cpp:404]     Test net output #0: acc_top_1 = 0.529858
I0210 16:05:11.177049 27601 solver.cpp:404]     Test net output #1: loss = 1.86103 (* 1 = 1.86103 loss)
I0210 16:05:16.063673 27601 solver.cpp:228] Iteration 380, loss = 1.20862
I0210 16:05:16.063709 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.6875
I0210 16:05:16.063721 27601 solver.cpp:244]     Train net output #1: loss = 1.20862 (* 1 = 1.20862 loss)
I0210 16:05:16.896049 27601 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0210 16:05:38.906733 27601 solver.cpp:228] Iteration 400, loss = 1.25049
I0210 16:05:38.906767 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.625
I0210 16:05:38.906780 27601 solver.cpp:244]     Train net output #1: loss = 1.25049 (* 1 = 1.25049 loss)
I0210 16:05:39.757766 27601 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0210 16:06:01.809110 27601 solver.cpp:228] Iteration 420, loss = 1.48092
I0210 16:06:01.809672 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.625
I0210 16:06:01.809725 27601 solver.cpp:244]     Train net output #1: loss = 1.48092 (* 1 = 1.48092 loss)
I0210 16:06:02.643182 27601 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0210 16:06:24.758306 27601 solver.cpp:228] Iteration 440, loss = 0.632055
I0210 16:06:24.758340 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.875
I0210 16:06:24.758352 27601 solver.cpp:244]     Train net output #1: loss = 0.632055 (* 1 = 0.632055 loss)
I0210 16:06:25.588515 27601 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0210 16:06:47.770809 27601 solver.cpp:228] Iteration 460, loss = 1.38484
I0210 16:06:47.771195 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.625
I0210 16:06:47.771214 27601 solver.cpp:244]     Train net output #1: loss = 1.38484 (* 1 = 1.38484 loss)
I0210 16:06:48.629832 27601 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0210 16:07:10.829242 27601 solver.cpp:228] Iteration 480, loss = 1.51858
I0210 16:07:10.829282 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.6875
I0210 16:07:10.829293 27601 solver.cpp:244]     Train net output #1: loss = 1.51858 (* 1 = 1.51858 loss)
I0210 16:07:11.652374 27601 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0210 16:07:33.854892 27601 solver.cpp:228] Iteration 500, loss = 1.2518
I0210 16:07:33.855232 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.5
I0210 16:07:33.855249 27601 solver.cpp:244]     Train net output #1: loss = 1.2518 (* 1 = 1.2518 loss)
I0210 16:07:34.689450 27601 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0210 16:07:56.888526 27601 solver.cpp:228] Iteration 520, loss = 0.999585
I0210 16:07:56.888563 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.75
I0210 16:07:56.888586 27601 solver.cpp:244]     Train net output #1: loss = 0.999585 (* 1 = 0.999585 loss)
I0210 16:07:57.717890 27601 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0210 16:08:19.905745 27601 solver.cpp:228] Iteration 540, loss = 1.29679
I0210 16:08:19.910724 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.6875
I0210 16:08:19.910740 27601 solver.cpp:244]     Train net output #1: loss = 1.29679 (* 1 = 1.29679 loss)
I0210 16:08:20.745379 27601 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0210 16:08:42.979884 27601 solver.cpp:228] Iteration 560, loss = 1.36629
I0210 16:08:42.979948 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.6875
I0210 16:08:42.979960 27601 solver.cpp:244]     Train net output #1: loss = 1.36629 (* 1 = 1.36629 loss)
I0210 16:08:43.816800 27601 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0210 16:08:47.292325 27601 solver.cpp:337] Iteration 564, Testing net (#0)
I0210 16:10:59.012281 27601 solver.cpp:404]     Test net output #0: acc_top_1 = 0.561443
I0210 16:10:59.018690 27601 solver.cpp:404]     Test net output #1: loss = 1.76655 (* 1 = 1.76655 loss)
I0210 16:11:17.569088 27601 solver.cpp:228] Iteration 580, loss = 1.36906
I0210 16:11:17.569138 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.625
I0210 16:11:17.569149 27601 solver.cpp:244]     Train net output #1: loss = 1.36906 (* 1 = 1.36906 loss)
I0210 16:11:18.398401 27601 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0210 16:11:40.401767 27601 solver.cpp:228] Iteration 600, loss = 1.58099
I0210 16:11:40.403889 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.5625
I0210 16:11:40.403908 27601 solver.cpp:244]     Train net output #1: loss = 1.58099 (* 1 = 1.58099 loss)
I0210 16:11:41.255136 27601 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0210 16:12:03.327910 27601 solver.cpp:228] Iteration 620, loss = 1.18939
I0210 16:12:03.327950 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.6875
I0210 16:12:03.327965 27601 solver.cpp:244]     Train net output #1: loss = 1.18939 (* 1 = 1.18939 loss)
I0210 16:12:04.157825 27601 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0210 16:12:26.294450 27601 solver.cpp:228] Iteration 640, loss = 1.19809
I0210 16:12:26.294849 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.5625
I0210 16:12:26.294867 27601 solver.cpp:244]     Train net output #1: loss = 1.19809 (* 1 = 1.19809 loss)
I0210 16:12:27.132977 27601 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0210 16:12:49.288128 27601 solver.cpp:228] Iteration 660, loss = 1.01812
I0210 16:12:49.288167 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.6875
I0210 16:12:49.288184 27601 solver.cpp:244]     Train net output #1: loss = 1.01812 (* 1 = 1.01812 loss)
I0210 16:12:50.139379 27601 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0210 16:13:12.327711 27601 solver.cpp:228] Iteration 680, loss = 0.246518
I0210 16:13:12.328040 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.9375
I0210 16:13:12.328060 27601 solver.cpp:244]     Train net output #1: loss = 0.246518 (* 1 = 0.246518 loss)
I0210 16:13:13.159333 27601 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0210 16:13:35.376087 27601 solver.cpp:228] Iteration 700, loss = 0.826893
I0210 16:13:35.376121 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.75
I0210 16:13:35.376132 27601 solver.cpp:244]     Train net output #1: loss = 0.826894 (* 1 = 0.826894 loss)
I0210 16:13:36.213711 27601 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0210 16:13:58.398854 27601 solver.cpp:228] Iteration 720, loss = 0.591687
I0210 16:13:58.399340 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.8125
I0210 16:13:58.399368 27601 solver.cpp:244]     Train net output #1: loss = 0.591687 (* 1 = 0.591687 loss)
I0210 16:13:59.231228 27601 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0210 16:14:21.422503 27601 solver.cpp:228] Iteration 740, loss = 0.509828
I0210 16:14:21.422541 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.875
I0210 16:14:21.422554 27601 solver.cpp:244]     Train net output #1: loss = 0.509829 (* 1 = 0.509829 loss)
I0210 16:14:22.255568 27601 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0210 16:14:34.951573 27601 solver.cpp:337] Iteration 752, Testing net (#0)
I0210 16:16:46.605762 27601 solver.cpp:404]     Test net output #0: acc_top_1 = 0.574042
I0210 16:16:46.608680 27601 solver.cpp:404]     Test net output #1: loss = 1.7961 (* 1 = 1.7961 loss)
I0210 16:16:56.055748 27601 solver.cpp:228] Iteration 760, loss = 0.932482
I0210 16:16:56.055783 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.75
I0210 16:16:56.055795 27601 solver.cpp:244]     Train net output #1: loss = 0.932482 (* 1 = 0.932482 loss)
I0210 16:16:56.882745 27601 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0210 16:17:18.880760 27601 solver.cpp:228] Iteration 780, loss = 0.803107
I0210 16:17:18.881140 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.75
I0210 16:17:18.881170 27601 solver.cpp:244]     Train net output #1: loss = 0.803107 (* 1 = 0.803107 loss)
I0210 16:17:19.702883 27601 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0210 16:17:41.783821 27601 solver.cpp:228] Iteration 800, loss = 0.138709
I0210 16:17:41.783861 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.9375
I0210 16:17:41.783872 27601 solver.cpp:244]     Train net output #1: loss = 0.138709 (* 1 = 0.138709 loss)
I0210 16:17:42.607843 27601 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0210 16:18:04.756954 27601 solver.cpp:228] Iteration 820, loss = 1.00341
I0210 16:18:04.757339 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.5625
I0210 16:18:04.757376 27601 solver.cpp:244]     Train net output #1: loss = 1.00341 (* 1 = 1.00341 loss)
I0210 16:18:05.602818 27601 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0210 16:18:27.775851 27601 solver.cpp:228] Iteration 840, loss = 0.784524
I0210 16:18:27.775887 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.6875
I0210 16:18:27.775910 27601 solver.cpp:244]     Train net output #1: loss = 0.784525 (* 1 = 0.784525 loss)
I0210 16:18:28.602073 27601 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0210 16:18:50.787780 27601 solver.cpp:228] Iteration 860, loss = 1.08278
I0210 16:18:50.795421 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.625
I0210 16:18:50.795459 27601 solver.cpp:244]     Train net output #1: loss = 1.08278 (* 1 = 1.08278 loss)
I0210 16:18:51.640439 27601 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0210 16:19:13.819427 27601 solver.cpp:228] Iteration 880, loss = 0.688741
I0210 16:19:13.819464 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.8125
I0210 16:19:13.819489 27601 solver.cpp:244]     Train net output #1: loss = 0.688741 (* 1 = 0.688741 loss)
I0210 16:19:14.665102 27601 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0210 16:19:36.814901 27601 solver.cpp:228] Iteration 900, loss = 1.05557
I0210 16:19:36.815233 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.8125
I0210 16:19:36.815260 27601 solver.cpp:244]     Train net output #1: loss = 1.05557 (* 1 = 1.05557 loss)
I0210 16:19:37.653491 27601 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0210 16:19:59.862756 27601 solver.cpp:228] Iteration 920, loss = 0.657548
I0210 16:19:59.862792 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.8125
I0210 16:19:59.862803 27601 solver.cpp:244]     Train net output #1: loss = 0.657548 (* 1 = 0.657548 loss)
I0210 16:20:00.698571 27601 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0210 16:20:22.576611 27601 solver.cpp:337] Iteration 940, Testing net (#0)
I0210 16:22:34.457592 27601 solver.cpp:404]     Test net output #0: acc_top_1 = 0.605109
I0210 16:22:34.458122 27601 solver.cpp:404]     Test net output #1: loss = 1.73701 (* 1 = 1.73701 loss)
I0210 16:22:34.779417 27601 solver.cpp:228] Iteration 940, loss = 0.597621
I0210 16:22:34.779469 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.8125
I0210 16:22:34.779485 27601 solver.cpp:244]     Train net output #1: loss = 0.597621 (* 1 = 0.597621 loss)
I0210 16:22:35.613571 27601 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0210 16:22:57.531949 27601 solver.cpp:228] Iteration 960, loss = 0.494929
I0210 16:22:57.531997 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.8125
I0210 16:22:57.532009 27601 solver.cpp:244]     Train net output #1: loss = 0.494929 (* 1 = 0.494929 loss)
I0210 16:22:58.372285 27601 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0210 16:23:20.414041 27601 solver.cpp:228] Iteration 980, loss = 0.374639
I0210 16:23:20.414494 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.9375
I0210 16:23:20.414521 27601 solver.cpp:244]     Train net output #1: loss = 0.374639 (* 1 = 0.374639 loss)
I0210 16:23:21.241359 27601 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0210 16:23:43.339738 27601 solver.cpp:228] Iteration 1000, loss = 0.182696
I0210 16:23:43.339789 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:23:43.339802 27601 solver.cpp:244]     Train net output #1: loss = 0.182696 (* 1 = 0.182696 loss)
I0210 16:23:44.174978 27601 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0210 16:24:06.328539 27601 solver.cpp:228] Iteration 1020, loss = 0.138235
I0210 16:24:06.328860 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.9375
I0210 16:24:06.328877 27601 solver.cpp:244]     Train net output #1: loss = 0.138235 (* 1 = 0.138235 loss)
I0210 16:24:07.164533 27601 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0210 16:24:29.300299 27601 solver.cpp:228] Iteration 1040, loss = 0.3421
I0210 16:24:29.300349 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.9375
I0210 16:24:29.300360 27601 solver.cpp:244]     Train net output #1: loss = 0.3421 (* 1 = 0.3421 loss)
I0210 16:24:30.127696 27601 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0210 16:24:52.270468 27601 solver.cpp:228] Iteration 1060, loss = 0.265018
I0210 16:24:52.275691 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.9375
I0210 16:24:52.275707 27601 solver.cpp:244]     Train net output #1: loss = 0.265018 (* 1 = 0.265018 loss)
I0210 16:24:53.111032 27601 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0210 16:25:15.265561 27601 solver.cpp:228] Iteration 1080, loss = 1.40489
I0210 16:25:15.265596 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.75
I0210 16:25:15.265609 27601 solver.cpp:244]     Train net output #1: loss = 1.40489 (* 1 = 1.40489 loss)
I0210 16:25:16.109403 27601 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0210 16:25:38.931139 27601 solver.cpp:228] Iteration 1100, loss = 0.375589
I0210 16:25:38.931546 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.8125
I0210 16:25:38.931571 27601 solver.cpp:244]     Train net output #1: loss = 0.375589 (* 1 = 0.375589 loss)
I0210 16:25:39.764194 27601 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0210 16:26:02.613059 27601 solver.cpp:228] Iteration 1120, loss = 0.446364
I0210 16:26:02.613106 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.75
I0210 16:26:02.613116 27601 solver.cpp:244]     Train net output #1: loss = 0.446364 (* 1 = 0.446364 loss)
I0210 16:26:03.455986 27601 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0210 16:26:11.500013 27601 solver.cpp:337] Iteration 1128, Testing net (#0)
I0210 16:28:23.309880 27601 solver.cpp:404]     Test net output #0: acc_top_1 = 0.556438
I0210 16:28:23.316756 27601 solver.cpp:404]     Test net output #1: loss = 2.31819 (* 1 = 2.31819 loss)
I0210 16:28:38.678753 27601 solver.cpp:228] Iteration 1140, loss = 0.284942
I0210 16:28:38.678791 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.9375
I0210 16:28:38.678803 27601 solver.cpp:244]     Train net output #1: loss = 0.284942 (* 1 = 0.284942 loss)
I0210 16:28:39.472335 27601 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0210 16:29:01.418611 27601 solver.cpp:228] Iteration 1160, loss = 0.17889
I0210 16:29:01.421102 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.875
I0210 16:29:01.421119 27601 solver.cpp:244]     Train net output #1: loss = 0.17889 (* 1 = 0.17889 loss)
I0210 16:29:02.250777 27601 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0210 16:29:24.309865 27601 solver.cpp:228] Iteration 1180, loss = 0.390904
I0210 16:29:24.309900 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.9375
I0210 16:29:24.309912 27601 solver.cpp:244]     Train net output #1: loss = 0.390903 (* 1 = 0.390903 loss)
I0210 16:29:25.151574 27601 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0210 16:29:47.274896 27601 solver.cpp:228] Iteration 1200, loss = 1.12243
I0210 16:29:47.275323 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.625
I0210 16:29:47.275351 27601 solver.cpp:244]     Train net output #1: loss = 1.12243 (* 1 = 1.12243 loss)
I0210 16:29:48.108862 27601 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0210 16:30:10.256320 27601 solver.cpp:228] Iteration 1220, loss = 0.251065
I0210 16:30:10.256371 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.9375
I0210 16:30:10.256382 27601 solver.cpp:244]     Train net output #1: loss = 0.251064 (* 1 = 0.251064 loss)
I0210 16:30:11.092821 27601 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0210 16:30:33.259701 27601 solver.cpp:228] Iteration 1240, loss = 0.627412
I0210 16:30:33.260135 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.75
I0210 16:30:33.260186 27601 solver.cpp:244]     Train net output #1: loss = 0.627411 (* 1 = 0.627411 loss)
I0210 16:30:34.101651 27601 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0210 16:30:56.279081 27601 solver.cpp:228] Iteration 1260, loss = 0.134212
I0210 16:30:56.279115 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:30:56.279126 27601 solver.cpp:244]     Train net output #1: loss = 0.134211 (* 1 = 0.134211 loss)
I0210 16:30:57.113108 27601 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0210 16:31:20.621603 27601 solver.cpp:228] Iteration 1280, loss = 1.18507
I0210 16:31:20.622071 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.875
I0210 16:31:20.622123 27601 solver.cpp:244]     Train net output #1: loss = 1.18507 (* 1 = 1.18507 loss)
I0210 16:31:21.458811 27601 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0210 16:31:43.643963 27601 solver.cpp:228] Iteration 1300, loss = 0.469058
I0210 16:31:43.644001 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.875
I0210 16:31:43.644023 27601 solver.cpp:244]     Train net output #1: loss = 0.469057 (* 1 = 0.469057 loss)
I0210 16:31:44.486258 27601 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0210 16:32:01.778486 27601 solver.cpp:337] Iteration 1316, Testing net (#0)
I0210 16:34:13.732439 27601 solver.cpp:404]     Test net output #0: acc_top_1 = 0.573179
I0210 16:34:13.732852 27601 solver.cpp:404]     Test net output #1: loss = 2.05471 (* 1 = 2.05471 loss)
I0210 16:34:14.896967 27601 sgd_solver.cpp:46] MultiStep Status: Iteration 1316, step = 1
I0210 16:34:18.628445 27601 solver.cpp:228] Iteration 1320, loss = 1.7721
I0210 16:34:18.628481 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.75
I0210 16:34:18.628504 27601 solver.cpp:244]     Train net output #1: loss = 1.7721 (* 1 = 1.7721 loss)
I0210 16:34:19.470167 27601 sgd_solver.cpp:106] Iteration 1320, lr = 0.0001
I0210 16:34:41.416676 27601 solver.cpp:228] Iteration 1340, loss = 0.1678
I0210 16:34:41.416712 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.875
I0210 16:34:41.416723 27601 solver.cpp:244]     Train net output #1: loss = 0.1678 (* 1 = 0.1678 loss)
I0210 16:34:42.247607 27601 sgd_solver.cpp:106] Iteration 1340, lr = 0.0001
I0210 16:35:04.903127 27601 solver.cpp:228] Iteration 1360, loss = 0.495923
I0210 16:35:04.903473 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.75
I0210 16:35:04.903491 27601 solver.cpp:244]     Train net output #1: loss = 0.495923 (* 1 = 0.495923 loss)
I0210 16:35:05.731611 27601 sgd_solver.cpp:106] Iteration 1360, lr = 0.0001
I0210 16:35:27.783819 27601 solver.cpp:228] Iteration 1380, loss = 0.256673
I0210 16:35:27.783869 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.875
I0210 16:35:27.783881 27601 solver.cpp:244]     Train net output #1: loss = 0.256672 (* 1 = 0.256672 loss)
I0210 16:35:28.623080 27601 sgd_solver.cpp:106] Iteration 1380, lr = 0.0001
I0210 16:35:50.765614 27601 solver.cpp:228] Iteration 1400, loss = 0.400773
I0210 16:35:50.765982 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.875
I0210 16:35:50.766001 27601 solver.cpp:244]     Train net output #1: loss = 0.400772 (* 1 = 0.400772 loss)
I0210 16:35:51.600940 27601 sgd_solver.cpp:106] Iteration 1400, lr = 0.0001
I0210 16:36:13.757087 27601 solver.cpp:228] Iteration 1420, loss = 0.379949
I0210 16:36:13.757122 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.875
I0210 16:36:13.757138 27601 solver.cpp:244]     Train net output #1: loss = 0.379948 (* 1 = 0.379948 loss)
I0210 16:36:14.589344 27601 sgd_solver.cpp:106] Iteration 1420, lr = 0.0001
I0210 16:36:36.754685 27601 solver.cpp:228] Iteration 1440, loss = 0.0138358
I0210 16:36:36.756414 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:36:36.756433 27601 solver.cpp:244]     Train net output #1: loss = 0.0138354 (* 1 = 0.0138354 loss)
I0210 16:36:37.584599 27601 sgd_solver.cpp:106] Iteration 1440, lr = 0.0001
I0210 16:36:59.796063 27601 solver.cpp:228] Iteration 1460, loss = 0.0376208
I0210 16:36:59.796104 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:36:59.796120 27601 solver.cpp:244]     Train net output #1: loss = 0.0376204 (* 1 = 0.0376204 loss)
I0210 16:37:00.639582 27601 sgd_solver.cpp:106] Iteration 1460, lr = 0.0001
I0210 16:37:22.832857 27601 solver.cpp:228] Iteration 1480, loss = 0.117033
I0210 16:37:22.833339 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.9375
I0210 16:37:22.833389 27601 solver.cpp:244]     Train net output #1: loss = 0.117033 (* 1 = 0.117033 loss)
I0210 16:37:23.681442 27601 sgd_solver.cpp:106] Iteration 1480, lr = 0.0001
I0210 16:37:45.924682 27601 solver.cpp:228] Iteration 1500, loss = 0.0258894
I0210 16:37:45.924715 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:37:45.924737 27601 solver.cpp:244]     Train net output #1: loss = 0.025889 (* 1 = 0.025889 loss)
I0210 16:37:46.764509 27601 sgd_solver.cpp:106] Iteration 1500, lr = 0.0001
I0210 16:37:50.216143 27601 solver.cpp:337] Iteration 1504, Testing net (#0)
I0210 16:40:02.460757 27601 solver.cpp:404]     Test net output #0: acc_top_1 = 0.708319
I0210 16:40:02.468456 27601 solver.cpp:404]     Test net output #1: loss = 1.40438 (* 1 = 1.40438 loss)
I0210 16:40:21.116366 27601 solver.cpp:228] Iteration 1520, loss = 0.0616647
I0210 16:40:21.116399 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:40:21.116412 27601 solver.cpp:244]     Train net output #1: loss = 0.0616643 (* 1 = 0.0616643 loss)
I0210 16:40:21.952405 27601 sgd_solver.cpp:106] Iteration 1520, lr = 0.0001
I0210 16:40:44.154870 27601 solver.cpp:228] Iteration 1540, loss = 0.0702233
I0210 16:40:44.155200 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:40:44.155223 27601 solver.cpp:244]     Train net output #1: loss = 0.0702229 (* 1 = 0.0702229 loss)
I0210 16:40:44.987224 27601 sgd_solver.cpp:106] Iteration 1540, lr = 0.0001
I0210 16:41:07.307389 27601 solver.cpp:228] Iteration 1560, loss = 0.0443414
I0210 16:41:07.307426 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:41:07.307437 27601 solver.cpp:244]     Train net output #1: loss = 0.044341 (* 1 = 0.044341 loss)
I0210 16:41:08.156087 27601 sgd_solver.cpp:106] Iteration 1560, lr = 0.0001
I0210 16:41:30.451552 27601 solver.cpp:228] Iteration 1580, loss = 0.118706
I0210 16:41:30.451951 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:41:30.452004 27601 solver.cpp:244]     Train net output #1: loss = 0.118706 (* 1 = 0.118706 loss)
I0210 16:41:31.293285 27601 sgd_solver.cpp:106] Iteration 1580, lr = 0.0001
I0210 16:41:53.579905 27601 solver.cpp:228] Iteration 1600, loss = 0.0260681
I0210 16:41:53.579946 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:41:53.579957 27601 solver.cpp:244]     Train net output #1: loss = 0.0260678 (* 1 = 0.0260678 loss)
I0210 16:41:54.430944 27601 sgd_solver.cpp:106] Iteration 1600, lr = 0.0001
I0210 16:42:16.732311 27601 solver.cpp:228] Iteration 1620, loss = 0.0100599
I0210 16:42:16.748317 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:42:16.748344 27601 solver.cpp:244]     Train net output #1: loss = 0.0100595 (* 1 = 0.0100595 loss)
I0210 16:42:17.569700 27601 sgd_solver.cpp:106] Iteration 1620, lr = 0.0001
I0210 16:42:39.843008 27601 solver.cpp:228] Iteration 1640, loss = 0.0309194
I0210 16:42:39.843065 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:42:39.843087 27601 solver.cpp:244]     Train net output #1: loss = 0.030919 (* 1 = 0.030919 loss)
I0210 16:42:40.688542 27601 sgd_solver.cpp:106] Iteration 1640, lr = 0.0001
I0210 16:43:02.953027 27601 solver.cpp:228] Iteration 1660, loss = 0.0157869
I0210 16:43:02.953364 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:43:02.953392 27601 solver.cpp:244]     Train net output #1: loss = 0.0157865 (* 1 = 0.0157865 loss)
I0210 16:43:03.789293 27601 sgd_solver.cpp:106] Iteration 1660, lr = 0.0001
I0210 16:43:26.074029 27601 solver.cpp:228] Iteration 1680, loss = 0.0643
I0210 16:43:26.074066 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.9375
I0210 16:43:26.074093 27601 solver.cpp:244]     Train net output #1: loss = 0.0642996 (* 1 = 0.0642996 loss)
I0210 16:43:26.923923 27601 sgd_solver.cpp:106] Iteration 1680, lr = 0.0001
I0210 16:43:39.612135 27601 solver.cpp:337] Iteration 1692, Testing net (#0)
I0210 16:45:51.447973 27601 solver.cpp:404]     Test net output #0: acc_top_1 = 0.712979
I0210 16:45:51.454290 27601 solver.cpp:404]     Test net output #1: loss = 1.49121 (* 1 = 1.49121 loss)
I0210 16:46:00.957859 27601 solver.cpp:228] Iteration 1700, loss = 0.0222143
I0210 16:46:00.957898 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:46:00.957909 27601 solver.cpp:244]     Train net output #1: loss = 0.0222139 (* 1 = 0.0222139 loss)
I0210 16:46:01.801580 27601 sgd_solver.cpp:106] Iteration 1700, lr = 0.0001
I0210 16:46:23.949141 27601 solver.cpp:228] Iteration 1720, loss = 0.0242724
I0210 16:46:23.949501 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:46:23.949530 27601 solver.cpp:244]     Train net output #1: loss = 0.024272 (* 1 = 0.024272 loss)
I0210 16:46:24.788079 27601 sgd_solver.cpp:106] Iteration 1720, lr = 0.0001
I0210 16:46:47.074895 27601 solver.cpp:228] Iteration 1740, loss = 0.025261
I0210 16:46:47.074931 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:46:47.074942 27601 solver.cpp:244]     Train net output #1: loss = 0.0252606 (* 1 = 0.0252606 loss)
I0210 16:46:47.917362 27601 sgd_solver.cpp:106] Iteration 1740, lr = 0.0001
I0210 16:47:10.190315 27601 solver.cpp:228] Iteration 1760, loss = 0.00897828
I0210 16:47:10.196121 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:47:10.196137 27601 solver.cpp:244]     Train net output #1: loss = 0.00897787 (* 1 = 0.00897787 loss)
I0210 16:47:11.024122 27601 sgd_solver.cpp:106] Iteration 1760, lr = 0.0001
I0210 16:47:33.336233 27601 solver.cpp:228] Iteration 1780, loss = 0.0164671
I0210 16:47:33.336279 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:47:33.336289 27601 solver.cpp:244]     Train net output #1: loss = 0.0164667 (* 1 = 0.0164667 loss)
I0210 16:47:34.167515 27601 sgd_solver.cpp:106] Iteration 1780, lr = 0.0001
I0210 16:47:56.493053 27601 solver.cpp:228] Iteration 1800, loss = 0.0540385
I0210 16:47:56.500805 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:47:56.500839 27601 solver.cpp:244]     Train net output #1: loss = 0.0540381 (* 1 = 0.0540381 loss)
I0210 16:47:57.346369 27601 sgd_solver.cpp:106] Iteration 1800, lr = 0.0001
I0210 16:48:19.619630 27601 solver.cpp:228] Iteration 1820, loss = 0.0327881
I0210 16:48:19.619669 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:48:19.619685 27601 solver.cpp:244]     Train net output #1: loss = 0.0327877 (* 1 = 0.0327877 loss)
I0210 16:48:20.469866 27601 sgd_solver.cpp:106] Iteration 1820, lr = 0.0001
I0210 16:48:42.738832 27601 solver.cpp:228] Iteration 1840, loss = 0.000869036
I0210 16:48:42.746130 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:48:42.746182 27601 solver.cpp:244]     Train net output #1: loss = 0.000868646 (* 1 = 0.000868646 loss)
I0210 16:48:43.586014 27601 sgd_solver.cpp:106] Iteration 1840, lr = 0.0001
I0210 16:49:05.860162 27601 solver.cpp:228] Iteration 1860, loss = 0.00118975
I0210 16:49:05.860206 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:49:05.860218 27601 solver.cpp:244]     Train net output #1: loss = 0.00118938 (* 1 = 0.00118938 loss)
I0210 16:49:06.702515 27601 sgd_solver.cpp:106] Iteration 1860, lr = 0.0001
I0210 16:49:28.667726 27601 solver.cpp:337] Iteration 1880, Testing net (#0)
I0210 16:51:40.494776 27601 solver.cpp:404]     Test net output #0: acc_top_1 = 0.715395
I0210 16:51:40.500381 27601 solver.cpp:404]     Test net output #1: loss = 1.58662 (* 1 = 1.58662 loss)
I0210 16:51:40.819926 27601 solver.cpp:228] Iteration 1880, loss = 0.122119
I0210 16:51:40.819957 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.9375
I0210 16:51:40.819967 27601 solver.cpp:244]     Train net output #1: loss = 0.122119 (* 1 = 0.122119 loss)
I0210 16:51:41.657258 27601 sgd_solver.cpp:106] Iteration 1880, lr = 0.0001
I0210 16:52:04.354254 27601 solver.cpp:228] Iteration 1900, loss = 0.0537495
I0210 16:52:04.354291 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:52:04.354303 27601 solver.cpp:244]     Train net output #1: loss = 0.0537492 (* 1 = 0.0537492 loss)
I0210 16:52:05.184283 27601 sgd_solver.cpp:106] Iteration 1900, lr = 0.0001
I0210 16:52:27.364179 27601 solver.cpp:228] Iteration 1920, loss = 0.00554687
I0210 16:52:27.364600 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:52:27.364619 27601 solver.cpp:244]     Train net output #1: loss = 0.00554649 (* 1 = 0.00554649 loss)
I0210 16:52:28.210314 27601 sgd_solver.cpp:106] Iteration 1920, lr = 0.0001
I0210 16:52:50.501309 27601 solver.cpp:228] Iteration 1940, loss = 0.00836363
I0210 16:52:50.501345 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:52:50.501356 27601 solver.cpp:244]     Train net output #1: loss = 0.00836326 (* 1 = 0.00836326 loss)
I0210 16:52:51.340453 27601 sgd_solver.cpp:106] Iteration 1940, lr = 0.0001
I0210 16:53:13.652034 27601 solver.cpp:228] Iteration 1960, loss = 0.0890305
I0210 16:53:13.652371 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.9375
I0210 16:53:13.652390 27601 solver.cpp:244]     Train net output #1: loss = 0.0890301 (* 1 = 0.0890301 loss)
I0210 16:53:14.494562 27601 sgd_solver.cpp:106] Iteration 1960, lr = 0.0001
I0210 16:53:36.760336 27601 solver.cpp:228] Iteration 1980, loss = 0.102567
I0210 16:53:36.760372 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:53:36.760383 27601 solver.cpp:244]     Train net output #1: loss = 0.102566 (* 1 = 0.102566 loss)
I0210 16:53:37.612031 27601 sgd_solver.cpp:106] Iteration 1980, lr = 0.0001
I0210 16:53:59.865324 27601 solver.cpp:228] Iteration 2000, loss = 0.00857827
I0210 16:53:59.865653 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:53:59.865669 27601 solver.cpp:244]     Train net output #1: loss = 0.00857788 (* 1 = 0.00857788 loss)
I0210 16:54:00.702234 27601 sgd_solver.cpp:106] Iteration 2000, lr = 0.0001
I0210 16:54:23.004961 27601 solver.cpp:228] Iteration 2020, loss = 0.0364456
I0210 16:54:23.004998 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:54:23.005009 27601 solver.cpp:244]     Train net output #1: loss = 0.0364452 (* 1 = 0.0364452 loss)
I0210 16:54:23.836078 27601 sgd_solver.cpp:106] Iteration 2020, lr = 0.0001
I0210 16:54:46.056874 27601 solver.cpp:228] Iteration 2040, loss = 0.134073
I0210 16:54:46.057368 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.9375
I0210 16:54:46.057420 27601 solver.cpp:244]     Train net output #1: loss = 0.134072 (* 1 = 0.134072 loss)
I0210 16:54:46.892544 27601 sgd_solver.cpp:106] Iteration 2040, lr = 0.0001
I0210 16:55:09.162853 27601 solver.cpp:228] Iteration 2060, loss = 0.0406796
I0210 16:55:09.162896 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:55:09.162909 27601 solver.cpp:244]     Train net output #1: loss = 0.0406792 (* 1 = 0.0406792 loss)
I0210 16:55:10.009892 27601 sgd_solver.cpp:106] Iteration 2060, lr = 0.0001
I0210 16:55:18.099046 27601 solver.cpp:337] Iteration 2068, Testing net (#0)
I0210 16:57:30.270531 27601 solver.cpp:404]     Test net output #0: acc_top_1 = 0.710563
I0210 16:57:30.279307 27601 solver.cpp:404]     Test net output #1: loss = 1.69736 (* 1 = 1.69736 loss)
I0210 16:57:44.299883 27601 solver.cpp:228] Iteration 2080, loss = 0.0682876
I0210 16:57:44.299926 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:57:44.299937 27601 solver.cpp:244]     Train net output #1: loss = 0.0682872 (* 1 = 0.0682872 loss)
I0210 16:57:45.138579 27601 sgd_solver.cpp:106] Iteration 2080, lr = 0.0001
I0210 16:58:07.204258 27601 solver.cpp:228] Iteration 2100, loss = 0.0155071
I0210 16:58:07.214200 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:58:07.214218 27601 solver.cpp:244]     Train net output #1: loss = 0.0155068 (* 1 = 0.0155068 loss)
I0210 16:58:08.043957 27601 sgd_solver.cpp:106] Iteration 2100, lr = 0.0001
I0210 16:58:30.185065 27601 solver.cpp:228] Iteration 2120, loss = 0.165139
I0210 16:58:30.185106 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.9375
I0210 16:58:30.185117 27601 solver.cpp:244]     Train net output #1: loss = 0.165139 (* 1 = 0.165139 loss)
I0210 16:58:31.017436 27601 sgd_solver.cpp:106] Iteration 2120, lr = 0.0001
I0210 16:58:53.247274 27601 solver.cpp:228] Iteration 2140, loss = 0.0102468
I0210 16:58:53.251770 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:58:53.251790 27601 solver.cpp:244]     Train net output #1: loss = 0.0102464 (* 1 = 0.0102464 loss)
I0210 16:58:54.088817 27601 sgd_solver.cpp:106] Iteration 2140, lr = 0.0001
I0210 16:59:16.339617 27601 solver.cpp:228] Iteration 2160, loss = 0.040686
I0210 16:59:16.339656 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:59:16.339673 27601 solver.cpp:244]     Train net output #1: loss = 0.0406856 (* 1 = 0.0406856 loss)
I0210 16:59:17.184378 27601 sgd_solver.cpp:106] Iteration 2160, lr = 0.0001
I0210 16:59:39.457171 27601 solver.cpp:228] Iteration 2180, loss = 0.00261764
I0210 16:59:39.457593 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 16:59:39.457617 27601 solver.cpp:244]     Train net output #1: loss = 0.00261725 (* 1 = 0.00261725 loss)
I0210 16:59:40.302350 27601 sgd_solver.cpp:106] Iteration 2180, lr = 0.0001
I0210 17:00:02.545380 27601 solver.cpp:228] Iteration 2200, loss = 0.00471881
I0210 17:00:02.545413 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:00:02.545424 27601 solver.cpp:244]     Train net output #1: loss = 0.0047184 (* 1 = 0.0047184 loss)
I0210 17:00:03.401193 27601 sgd_solver.cpp:106] Iteration 2200, lr = 0.0001
I0210 17:00:25.647600 27601 solver.cpp:228] Iteration 2220, loss = 0.00283285
I0210 17:00:25.660104 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:00:25.660130 27601 solver.cpp:244]     Train net output #1: loss = 0.00283244 (* 1 = 0.00283244 loss)
I0210 17:00:26.496893 27601 sgd_solver.cpp:106] Iteration 2220, lr = 0.0001
I0210 17:00:48.749508 27601 solver.cpp:228] Iteration 2240, loss = 0.000238873
I0210 17:00:48.749569 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:00:48.749601 27601 solver.cpp:244]     Train net output #1: loss = 0.000238472 (* 1 = 0.000238472 loss)
I0210 17:00:49.599759 27601 sgd_solver.cpp:106] Iteration 2240, lr = 0.0001
I0210 17:01:06.908159 27601 solver.cpp:337] Iteration 2256, Testing net (#0)
I0210 17:03:18.706874 27601 solver.cpp:404]     Test net output #0: acc_top_1 = 0.712461
I0210 17:03:18.717391 27601 solver.cpp:404]     Test net output #1: loss = 1.7702 (* 1 = 1.7702 loss)
I0210 17:03:23.611256 27601 solver.cpp:228] Iteration 2260, loss = 0.00941583
I0210 17:03:23.611299 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:03:23.611311 27601 solver.cpp:244]     Train net output #1: loss = 0.00941543 (* 1 = 0.00941543 loss)
I0210 17:03:24.445891 27601 sgd_solver.cpp:106] Iteration 2260, lr = 0.0001
I0210 17:03:46.420426 27601 solver.cpp:228] Iteration 2280, loss = 0.0284847
I0210 17:03:46.420472 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:03:46.420483 27601 solver.cpp:244]     Train net output #1: loss = 0.0284843 (* 1 = 0.0284843 loss)
I0210 17:03:47.257048 27601 sgd_solver.cpp:106] Iteration 2280, lr = 0.0001
I0210 17:04:09.383810 27601 solver.cpp:228] Iteration 2300, loss = 0.00146212
I0210 17:04:09.384125 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:04:09.384141 27601 solver.cpp:244]     Train net output #1: loss = 0.00146171 (* 1 = 0.00146171 loss)
I0210 17:04:10.217751 27601 sgd_solver.cpp:106] Iteration 2300, lr = 0.0001
I0210 17:04:32.398900 27601 solver.cpp:228] Iteration 2320, loss = 0.00988212
I0210 17:04:32.398928 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:04:32.398949 27601 solver.cpp:244]     Train net output #1: loss = 0.00988172 (* 1 = 0.00988172 loss)
I0210 17:04:33.229632 27601 sgd_solver.cpp:106] Iteration 2320, lr = 0.0001
I0210 17:04:55.510330 27601 solver.cpp:228] Iteration 2340, loss = 0.00560356
I0210 17:04:55.522756 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:04:55.522773 27601 solver.cpp:244]     Train net output #1: loss = 0.00560316 (* 1 = 0.00560316 loss)
I0210 17:04:56.342839 27601 sgd_solver.cpp:106] Iteration 2340, lr = 0.0001
I0210 17:05:18.630539 27601 solver.cpp:228] Iteration 2360, loss = 0.0101919
I0210 17:05:18.630589 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:05:18.630601 27601 solver.cpp:244]     Train net output #1: loss = 0.0101915 (* 1 = 0.0101915 loss)
I0210 17:05:19.479881 27601 sgd_solver.cpp:106] Iteration 2360, lr = 0.0001
I0210 17:05:41.739589 27601 solver.cpp:228] Iteration 2380, loss = 0.00114693
I0210 17:05:41.751899 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:05:41.751930 27601 solver.cpp:244]     Train net output #1: loss = 0.00114652 (* 1 = 0.00114652 loss)
I0210 17:05:42.576923 27601 sgd_solver.cpp:106] Iteration 2380, lr = 0.0001
I0210 17:06:04.835870 27601 solver.cpp:228] Iteration 2400, loss = 0.00578228
I0210 17:06:04.835911 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:06:04.835922 27601 solver.cpp:244]     Train net output #1: loss = 0.00578188 (* 1 = 0.00578188 loss)
I0210 17:06:05.687261 27601 sgd_solver.cpp:106] Iteration 2400, lr = 0.0001
I0210 17:06:27.940506 27601 solver.cpp:228] Iteration 2420, loss = 0.0103595
I0210 17:06:27.942407 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:06:27.942440 27601 solver.cpp:244]     Train net output #1: loss = 0.0103591 (* 1 = 0.0103591 loss)
I0210 17:06:28.786505 27601 sgd_solver.cpp:106] Iteration 2420, lr = 0.0001
I0210 17:06:51.004284 27601 solver.cpp:228] Iteration 2440, loss = 0.0194602
I0210 17:06:51.004324 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:06:51.004336 27601 solver.cpp:244]     Train net output #1: loss = 0.0194597 (* 1 = 0.0194597 loss)
I0210 17:06:51.855373 27601 sgd_solver.cpp:106] Iteration 2440, lr = 0.0001
I0210 17:06:55.334513 27601 solver.cpp:337] Iteration 2444, Testing net (#0)
I0210 17:08:21.623646 27601 blocking_queue.cpp:50] Data layer prefetch queue empty
I0210 17:09:07.121454 27601 solver.cpp:404]     Test net output #0: acc_top_1 = 0.712634
I0210 17:09:07.130436 27601 solver.cpp:404]     Test net output #1: loss = 1.81621 (* 1 = 1.81621 loss)
I0210 17:09:25.685159 27601 solver.cpp:228] Iteration 2460, loss = 0.000796318
I0210 17:09:25.685199 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:09:25.685210 27601 solver.cpp:244]     Train net output #1: loss = 0.000795904 (* 1 = 0.000795904 loss)
I0210 17:09:26.500516 27601 sgd_solver.cpp:106] Iteration 2460, lr = 0.0001
I0210 17:09:48.566300 27601 solver.cpp:228] Iteration 2480, loss = 0.0882558
I0210 17:09:48.572537 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.9375
I0210 17:09:48.572597 27601 solver.cpp:244]     Train net output #1: loss = 0.0882554 (* 1 = 0.0882554 loss)
I0210 17:09:49.410928 27601 sgd_solver.cpp:106] Iteration 2480, lr = 0.0001
I0210 17:10:11.588107 27601 solver.cpp:228] Iteration 2500, loss = 0.00198556
I0210 17:10:11.588143 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:10:11.588155 27601 solver.cpp:244]     Train net output #1: loss = 0.00198514 (* 1 = 0.00198514 loss)
I0210 17:10:12.416538 27601 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0210 17:10:34.662865 27601 solver.cpp:228] Iteration 2520, loss = 0.0114992
I0210 17:10:34.663388 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:10:34.663439 27601 solver.cpp:244]     Train net output #1: loss = 0.0114988 (* 1 = 0.0114988 loss)
I0210 17:10:35.500066 27601 sgd_solver.cpp:106] Iteration 2520, lr = 0.0001
I0210 17:10:57.773800 27601 solver.cpp:228] Iteration 2540, loss = 0.00244261
I0210 17:10:57.773838 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:10:57.773849 27601 solver.cpp:244]     Train net output #1: loss = 0.00244219 (* 1 = 0.00244219 loss)
I0210 17:10:58.608497 27601 sgd_solver.cpp:106] Iteration 2540, lr = 0.0001
I0210 17:11:20.905668 27601 solver.cpp:228] Iteration 2560, loss = 0.00862268
I0210 17:11:20.906235 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:11:20.906265 27601 solver.cpp:244]     Train net output #1: loss = 0.00862226 (* 1 = 0.00862226 loss)
I0210 17:11:21.733835 27601 sgd_solver.cpp:106] Iteration 2560, lr = 0.0001
I0210 17:11:44.678252 27601 solver.cpp:228] Iteration 2580, loss = 0.0026802
I0210 17:11:44.678306 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:11:44.678319 27601 solver.cpp:244]     Train net output #1: loss = 0.00267978 (* 1 = 0.00267978 loss)
I0210 17:11:45.518463 27601 sgd_solver.cpp:106] Iteration 2580, lr = 0.0001
I0210 17:12:07.763670 27601 solver.cpp:228] Iteration 2600, loss = 0.00066155
I0210 17:12:07.764673 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:12:07.764724 27601 solver.cpp:244]     Train net output #1: loss = 0.000661126 (* 1 = 0.000661126 loss)
I0210 17:12:08.609556 27601 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0210 17:12:30.855620 27601 solver.cpp:228] Iteration 2620, loss = 7.20341e-05
I0210 17:12:30.855666 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:12:30.855677 27601 solver.cpp:244]     Train net output #1: loss = 7.1612e-05 (* 1 = 7.1612e-05 loss)
I0210 17:12:31.689888 27601 sgd_solver.cpp:106] Iteration 2620, lr = 0.0001
I0210 17:12:44.383539 27601 solver.cpp:337] Iteration 2632, Testing net (#0)
I0210 17:14:56.609334 27601 solver.cpp:404]     Test net output #0: acc_top_1 = 0.714014
I0210 17:14:56.609827 27601 solver.cpp:404]     Test net output #1: loss = 1.86181 (* 1 = 1.86181 loss)
I0210 17:14:57.777896 27601 sgd_solver.cpp:46] MultiStep Status: Iteration 2632, step = 2
I0210 17:15:06.747256 27601 solver.cpp:228] Iteration 2640, loss = 0.00243124
I0210 17:15:06.747300 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:15:06.747311 27601 solver.cpp:244]     Train net output #1: loss = 0.00243082 (* 1 = 0.00243082 loss)
I0210 17:15:07.567414 27601 sgd_solver.cpp:106] Iteration 2640, lr = 1e-05
I0210 17:15:29.592677 27601 solver.cpp:228] Iteration 2660, loss = 0.000362815
I0210 17:15:29.593210 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:15:29.593262 27601 solver.cpp:244]     Train net output #1: loss = 0.000362398 (* 1 = 0.000362398 loss)
I0210 17:15:30.417469 27601 sgd_solver.cpp:106] Iteration 2660, lr = 1e-05
I0210 17:15:52.525516 27601 solver.cpp:228] Iteration 2680, loss = 0.00558638
I0210 17:15:52.525553 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:15:52.525565 27601 solver.cpp:244]     Train net output #1: loss = 0.00558596 (* 1 = 0.00558596 loss)
I0210 17:15:53.356513 27601 sgd_solver.cpp:106] Iteration 2680, lr = 1e-05
I0210 17:16:15.533563 27601 solver.cpp:228] Iteration 2700, loss = 0.00563037
I0210 17:16:15.533957 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:16:15.533983 27601 solver.cpp:244]     Train net output #1: loss = 0.00562995 (* 1 = 0.00562995 loss)
I0210 17:16:16.372962 27601 sgd_solver.cpp:106] Iteration 2700, lr = 1e-05
I0210 17:16:38.608587 27601 solver.cpp:228] Iteration 2720, loss = 0.00721338
I0210 17:16:38.608623 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:16:38.608634 27601 solver.cpp:244]     Train net output #1: loss = 0.00721297 (* 1 = 0.00721297 loss)
I0210 17:16:39.455715 27601 sgd_solver.cpp:106] Iteration 2720, lr = 1e-05
I0210 17:17:01.752948 27601 solver.cpp:228] Iteration 2740, loss = 0.00122523
I0210 17:17:01.753417 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:17:01.753453 27601 solver.cpp:244]     Train net output #1: loss = 0.00122482 (* 1 = 0.00122482 loss)
I0210 17:17:02.588392 27601 sgd_solver.cpp:106] Iteration 2740, lr = 1e-05
I0210 17:17:24.874899 27601 solver.cpp:228] Iteration 2760, loss = 0.00718853
I0210 17:17:24.874951 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:17:24.874961 27601 solver.cpp:244]     Train net output #1: loss = 0.00718811 (* 1 = 0.00718811 loss)
I0210 17:17:25.715011 27601 sgd_solver.cpp:106] Iteration 2760, lr = 1e-05
I0210 17:17:47.984997 27601 solver.cpp:228] Iteration 2780, loss = 0.00539312
I0210 17:17:47.985368 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:17:47.985383 27601 solver.cpp:244]     Train net output #1: loss = 0.00539271 (* 1 = 0.00539271 loss)
I0210 17:17:48.817284 27601 sgd_solver.cpp:106] Iteration 2780, lr = 1e-05
I0210 17:18:11.059578 27601 solver.cpp:228] Iteration 2800, loss = 0.0107885
I0210 17:18:11.059629 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:18:11.059641 27601 solver.cpp:244]     Train net output #1: loss = 0.0107881 (* 1 = 0.0107881 loss)
I0210 17:18:11.896936 27601 sgd_solver.cpp:106] Iteration 2800, lr = 1e-05
I0210 17:18:33.810796 27601 solver.cpp:337] Iteration 2820, Testing net (#0)
I0210 17:20:46.037889 27601 solver.cpp:404]     Test net output #0: acc_top_1 = 0.714532
I0210 17:20:46.047116 27601 solver.cpp:404]     Test net output #1: loss = 1.86616 (* 1 = 1.86616 loss)
I0210 17:20:46.367312 27601 solver.cpp:228] Iteration 2820, loss = 0.000624311
I0210 17:20:46.367350 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:20:46.367363 27601 solver.cpp:244]     Train net output #1: loss = 0.000623899 (* 1 = 0.000623899 loss)
I0210 17:20:47.209008 27601 sgd_solver.cpp:106] Iteration 2820, lr = 1e-05
I0210 17:21:09.189083 27601 solver.cpp:228] Iteration 2840, loss = 0.00867773
I0210 17:21:09.189121 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:21:09.189131 27601 solver.cpp:244]     Train net output #1: loss = 0.00867731 (* 1 = 0.00867731 loss)
I0210 17:21:10.026492 27601 sgd_solver.cpp:106] Iteration 2840, lr = 1e-05
I0210 17:21:32.115578 27601 solver.cpp:228] Iteration 2860, loss = 0.00170412
I0210 17:21:32.115931 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:21:32.115948 27601 solver.cpp:244]     Train net output #1: loss = 0.00170369 (* 1 = 0.00170369 loss)
I0210 17:21:32.934273 27601 sgd_solver.cpp:106] Iteration 2860, lr = 1e-05
I0210 17:21:55.092572 27601 solver.cpp:228] Iteration 2880, loss = 0.00435433
I0210 17:21:55.092609 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:21:55.092620 27601 solver.cpp:244]     Train net output #1: loss = 0.00435391 (* 1 = 0.00435391 loss)
I0210 17:21:55.939817 27601 sgd_solver.cpp:106] Iteration 2880, lr = 1e-05
I0210 17:22:18.198323 27601 solver.cpp:228] Iteration 2900, loss = 0.00507496
I0210 17:22:18.198694 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:22:18.198710 27601 solver.cpp:244]     Train net output #1: loss = 0.00507453 (* 1 = 0.00507453 loss)
I0210 17:22:19.038837 27601 sgd_solver.cpp:106] Iteration 2900, lr = 1e-05
I0210 17:22:41.306061 27601 solver.cpp:228] Iteration 2920, loss = 0.00261741
I0210 17:22:41.306097 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:22:41.306108 27601 solver.cpp:244]     Train net output #1: loss = 0.00261698 (* 1 = 0.00261698 loss)
I0210 17:22:42.159152 27601 sgd_solver.cpp:106] Iteration 2920, lr = 1e-05
I0210 17:23:04.442364 27601 solver.cpp:228] Iteration 2940, loss = 0.00364839
I0210 17:23:04.442662 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:23:04.442680 27601 solver.cpp:244]     Train net output #1: loss = 0.00364796 (* 1 = 0.00364796 loss)
I0210 17:23:05.292104 27601 sgd_solver.cpp:106] Iteration 2940, lr = 1e-05
I0210 17:23:27.596654 27601 solver.cpp:228] Iteration 2960, loss = 0.00213477
I0210 17:23:27.596689 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:23:27.596700 27601 solver.cpp:244]     Train net output #1: loss = 0.00213434 (* 1 = 0.00213434 loss)
I0210 17:23:28.437391 27601 sgd_solver.cpp:106] Iteration 2960, lr = 1e-05
I0210 17:23:50.720506 27601 solver.cpp:228] Iteration 2980, loss = 0.00591603
I0210 17:23:50.720823 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:23:50.720837 27601 solver.cpp:244]     Train net output #1: loss = 0.0059156 (* 1 = 0.0059156 loss)
I0210 17:23:51.572614 27601 sgd_solver.cpp:106] Iteration 2980, lr = 1e-05
I0210 17:24:13.832438 27601 solver.cpp:228] Iteration 3000, loss = 0.00091243
I0210 17:24:13.832480 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:24:13.832491 27601 solver.cpp:244]     Train net output #1: loss = 0.000911998 (* 1 = 0.000911998 loss)
I0210 17:24:14.680253 27601 sgd_solver.cpp:106] Iteration 3000, lr = 1e-05
I0210 17:24:22.770419 27601 solver.cpp:337] Iteration 3008, Testing net (#0)
I0210 17:26:34.728631 27601 solver.cpp:404]     Test net output #0: acc_top_1 = 0.714877
I0210 17:26:34.729104 27601 solver.cpp:404]     Test net output #1: loss = 1.86813 (* 1 = 1.86813 loss)
I0210 17:26:48.739413 27601 solver.cpp:228] Iteration 3020, loss = 0.00410313
I0210 17:26:48.739454 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:26:48.739469 27601 solver.cpp:244]     Train net output #1: loss = 0.0041027 (* 1 = 0.0041027 loss)
I0210 17:26:49.579179 27601 sgd_solver.cpp:106] Iteration 3020, lr = 1e-05
I0210 17:27:12.330273 27601 solver.cpp:228] Iteration 3040, loss = 0.000342356
I0210 17:27:12.332427 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:27:12.332459 27601 solver.cpp:244]     Train net output #1: loss = 0.000341928 (* 1 = 0.000341928 loss)
I0210 17:27:13.161082 27601 sgd_solver.cpp:106] Iteration 3040, lr = 1e-05
I0210 17:27:35.273488 27601 solver.cpp:228] Iteration 3060, loss = 0.000319443
I0210 17:27:35.273527 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:27:35.273537 27601 solver.cpp:244]     Train net output #1: loss = 0.000319014 (* 1 = 0.000319014 loss)
I0210 17:27:36.101367 27601 sgd_solver.cpp:106] Iteration 3060, lr = 1e-05
I0210 17:27:59.668615 27601 solver.cpp:228] Iteration 3080, loss = 0.00324727
I0210 17:27:59.669121 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:27:59.669172 27601 solver.cpp:244]     Train net output #1: loss = 0.00324684 (* 1 = 0.00324684 loss)
I0210 17:28:00.519233 27601 sgd_solver.cpp:106] Iteration 3080, lr = 1e-05
I0210 17:28:22.794116 27601 solver.cpp:228] Iteration 3100, loss = 0.00591623
I0210 17:28:22.794157 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:28:22.794168 27601 solver.cpp:244]     Train net output #1: loss = 0.0059158 (* 1 = 0.0059158 loss)
I0210 17:28:23.628517 27601 sgd_solver.cpp:106] Iteration 3100, lr = 1e-05
I0210 17:28:45.900310 27601 solver.cpp:228] Iteration 3120, loss = 0.0017267
I0210 17:28:45.900764 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:28:45.900790 27601 solver.cpp:244]     Train net output #1: loss = 0.00172627 (* 1 = 0.00172627 loss)
I0210 17:28:46.741772 27601 sgd_solver.cpp:106] Iteration 3120, lr = 1e-05
I0210 17:29:09.008862 27601 solver.cpp:228] Iteration 3140, loss = 0.00550223
I0210 17:29:09.008888 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:29:09.008900 27601 solver.cpp:244]     Train net output #1: loss = 0.0055018 (* 1 = 0.0055018 loss)
I0210 17:29:09.847182 27601 sgd_solver.cpp:106] Iteration 3140, lr = 1e-05
I0210 17:29:32.113858 27601 solver.cpp:228] Iteration 3160, loss = 7.54253e-05
I0210 17:29:32.114192 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:29:32.114209 27601 solver.cpp:244]     Train net output #1: loss = 7.4997e-05 (* 1 = 7.4997e-05 loss)
I0210 17:29:32.955694 27601 sgd_solver.cpp:106] Iteration 3160, lr = 1e-05
I0210 17:29:55.235040 27601 solver.cpp:228] Iteration 3180, loss = 0.00134029
I0210 17:29:55.235090 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:29:55.235101 27601 solver.cpp:244]     Train net output #1: loss = 0.00133986 (* 1 = 0.00133986 loss)
I0210 17:29:56.088532 27601 sgd_solver.cpp:106] Iteration 3180, lr = 1e-05
I0210 17:30:13.418045 27601 solver.cpp:337] Iteration 3196, Testing net (#0)
I0210 17:32:25.231760 27601 solver.cpp:404]     Test net output #0: acc_top_1 = 0.714705
I0210 17:32:25.232265 27601 solver.cpp:404]     Test net output #1: loss = 1.87359 (* 1 = 1.87359 loss)
I0210 17:32:30.124562 27601 solver.cpp:228] Iteration 3200, loss = 0.0112924
I0210 17:32:30.124594 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:32:30.124605 27601 solver.cpp:244]     Train net output #1: loss = 0.011292 (* 1 = 0.011292 loss)
I0210 17:32:30.947926 27601 sgd_solver.cpp:106] Iteration 3200, lr = 1e-05
I0210 17:32:52.982784 27601 solver.cpp:228] Iteration 3220, loss = 0.00215237
I0210 17:32:52.982825 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:32:52.982836 27601 solver.cpp:244]     Train net output #1: loss = 0.00215194 (* 1 = 0.00215194 loss)
I0210 17:32:53.832152 27601 sgd_solver.cpp:106] Iteration 3220, lr = 1e-05
I0210 17:33:15.951529 27601 solver.cpp:228] Iteration 3240, loss = 0.00489181
I0210 17:33:15.954881 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:33:15.954897 27601 solver.cpp:244]     Train net output #1: loss = 0.00489138 (* 1 = 0.00489138 loss)
I0210 17:33:16.784324 27601 sgd_solver.cpp:106] Iteration 3240, lr = 1e-05
I0210 17:33:38.948972 27601 solver.cpp:228] Iteration 3260, loss = 0.000128226
I0210 17:33:38.949012 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:33:38.949023 27601 solver.cpp:244]     Train net output #1: loss = 0.000127797 (* 1 = 0.000127797 loss)
I0210 17:33:39.796849 27601 sgd_solver.cpp:106] Iteration 3260, lr = 1e-05
I0210 17:34:01.997076 27601 solver.cpp:228] Iteration 3280, loss = 0.00192128
I0210 17:34:01.997558 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:34:01.997586 27601 solver.cpp:244]     Train net output #1: loss = 0.00192085 (* 1 = 0.00192085 loss)
I0210 17:34:02.835146 27601 sgd_solver.cpp:106] Iteration 3280, lr = 1e-05
I0210 17:34:25.121865 27601 solver.cpp:228] Iteration 3300, loss = 0.00503502
I0210 17:34:25.121901 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:34:25.121913 27601 solver.cpp:244]     Train net output #1: loss = 0.00503459 (* 1 = 0.00503459 loss)
I0210 17:34:25.963446 27601 sgd_solver.cpp:106] Iteration 3300, lr = 1e-05
I0210 17:34:48.238276 27601 solver.cpp:228] Iteration 3320, loss = 0.000688182
I0210 17:34:48.238685 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:34:48.238719 27601 solver.cpp:244]     Train net output #1: loss = 0.000687752 (* 1 = 0.000687752 loss)
I0210 17:34:49.075829 27601 sgd_solver.cpp:106] Iteration 3320, lr = 1e-05
I0210 17:35:11.346318 27601 solver.cpp:228] Iteration 3340, loss = 0.0234931
I0210 17:35:11.346354 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:35:11.346364 27601 solver.cpp:244]     Train net output #1: loss = 0.0234927 (* 1 = 0.0234927 loss)
I0210 17:35:12.189918 27601 sgd_solver.cpp:106] Iteration 3340, lr = 1e-05
I0210 17:35:34.464898 27601 solver.cpp:228] Iteration 3360, loss = 0.011294
I0210 17:35:34.467022 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:35:34.467047 27601 solver.cpp:244]     Train net output #1: loss = 0.0112936 (* 1 = 0.0112936 loss)
I0210 17:35:35.299836 27601 sgd_solver.cpp:106] Iteration 3360, lr = 1e-05
I0210 17:35:57.576392 27601 solver.cpp:228] Iteration 3380, loss = 0.00224538
I0210 17:35:57.576431 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:35:57.576454 27601 solver.cpp:244]     Train net output #1: loss = 0.00224495 (* 1 = 0.00224495 loss)
I0210 17:35:58.415619 27601 sgd_solver.cpp:106] Iteration 3380, lr = 1e-05
I0210 17:36:01.875629 27601 solver.cpp:337] Iteration 3384, Testing net (#0)
I0210 17:38:13.542582 27601 solver.cpp:404]     Test net output #0: acc_top_1 = 0.714532
I0210 17:38:13.542891 27601 solver.cpp:404]     Test net output #1: loss = 1.87847 (* 1 = 1.87847 loss)
I0210 17:38:32.087887 27601 solver.cpp:228] Iteration 3400, loss = 0.0074338
I0210 17:38:32.087919 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:38:32.087942 27601 solver.cpp:244]     Train net output #1: loss = 0.00743337 (* 1 = 0.00743337 loss)
I0210 17:38:32.910185 27601 sgd_solver.cpp:106] Iteration 3400, lr = 1e-05
I0210 17:38:54.967962 27601 solver.cpp:228] Iteration 3420, loss = 0.0115139
I0210 17:38:54.968304 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:38:54.968323 27601 solver.cpp:244]     Train net output #1: loss = 0.0115135 (* 1 = 0.0115135 loss)
I0210 17:38:55.814304 27601 sgd_solver.cpp:106] Iteration 3420, lr = 1e-05
I0210 17:39:18.006744 27601 solver.cpp:228] Iteration 3440, loss = 0.00260516
I0210 17:39:18.006789 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:39:18.006803 27601 solver.cpp:244]     Train net output #1: loss = 0.00260473 (* 1 = 0.00260473 loss)
I0210 17:39:18.851377 27601 sgd_solver.cpp:106] Iteration 3440, lr = 1e-05
I0210 17:39:41.101899 27601 solver.cpp:228] Iteration 3460, loss = 0.0105332
I0210 17:39:41.102465 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:39:41.102481 27601 solver.cpp:244]     Train net output #1: loss = 0.0105327 (* 1 = 0.0105327 loss)
I0210 17:39:41.950801 27601 sgd_solver.cpp:106] Iteration 3460, lr = 1e-05
I0210 17:40:04.232031 27601 solver.cpp:228] Iteration 3480, loss = 0.00432812
I0210 17:40:04.232085 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:40:04.232098 27601 solver.cpp:244]     Train net output #1: loss = 0.0043277 (* 1 = 0.0043277 loss)
I0210 17:40:05.059464 27601 sgd_solver.cpp:106] Iteration 3480, lr = 1e-05
I0210 17:40:27.348233 27601 solver.cpp:228] Iteration 3500, loss = 0.000654109
I0210 17:40:27.348611 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:40:27.348630 27601 solver.cpp:244]     Train net output #1: loss = 0.000653682 (* 1 = 0.000653682 loss)
I0210 17:40:28.189589 27601 sgd_solver.cpp:106] Iteration 3500, lr = 1e-05
I0210 17:40:50.436586 27601 solver.cpp:228] Iteration 3520, loss = 0.00334729
I0210 17:40:50.436630 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:40:50.436641 27601 solver.cpp:244]     Train net output #1: loss = 0.00334687 (* 1 = 0.00334687 loss)
I0210 17:40:51.288004 27601 sgd_solver.cpp:106] Iteration 3520, lr = 1e-05
I0210 17:41:13.568599 27601 solver.cpp:228] Iteration 3540, loss = 0.000224876
I0210 17:41:13.569020 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:41:13.569043 27601 solver.cpp:244]     Train net output #1: loss = 0.00022445 (* 1 = 0.00022445 loss)
I0210 17:41:14.398099 27601 sgd_solver.cpp:106] Iteration 3540, lr = 1e-05
I0210 17:41:36.705412 27601 solver.cpp:228] Iteration 3560, loss = 0.00145036
I0210 17:41:36.705453 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:41:36.705466 27601 solver.cpp:244]     Train net output #1: loss = 0.00144993 (* 1 = 0.00144993 loss)
I0210 17:41:37.547113 27601 sgd_solver.cpp:106] Iteration 3560, lr = 1e-05
I0210 17:41:50.243692 27601 solver.cpp:337] Iteration 3572, Testing net (#0)
I0210 17:44:02.436820 27601 solver.cpp:404]     Test net output #0: acc_top_1 = 0.713152
I0210 17:44:02.437162 27601 solver.cpp:404]     Test net output #1: loss = 1.88394 (* 1 = 1.88394 loss)
I0210 17:44:11.872990 27601 solver.cpp:228] Iteration 3580, loss = 0.00913677
I0210 17:44:11.873024 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:44:11.873035 27601 solver.cpp:244]     Train net output #1: loss = 0.00913635 (* 1 = 0.00913635 loss)
I0210 17:44:12.701458 27601 sgd_solver.cpp:106] Iteration 3580, lr = 1e-05
I0210 17:44:35.381085 27601 solver.cpp:228] Iteration 3600, loss = 0.0120651
I0210 17:44:35.381412 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:44:35.381428 27601 solver.cpp:244]     Train net output #1: loss = 0.0120647 (* 1 = 0.0120647 loss)
I0210 17:44:36.221411 27601 sgd_solver.cpp:106] Iteration 3600, lr = 1e-05
I0210 17:44:58.329984 27601 solver.cpp:228] Iteration 3620, loss = 0.00383026
I0210 17:44:58.330030 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:44:58.330041 27601 solver.cpp:244]     Train net output #1: loss = 0.00382984 (* 1 = 0.00382984 loss)
I0210 17:44:59.167524 27601 sgd_solver.cpp:106] Iteration 3620, lr = 1e-05
I0210 17:45:21.356179 27601 solver.cpp:228] Iteration 3640, loss = 0.00127923
I0210 17:45:21.356544 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:45:21.356564 27601 solver.cpp:244]     Train net output #1: loss = 0.00127881 (* 1 = 0.00127881 loss)
I0210 17:45:22.211733 27601 sgd_solver.cpp:106] Iteration 3640, lr = 1e-05
I0210 17:45:44.455500 27601 solver.cpp:228] Iteration 3660, loss = 0.0575718
I0210 17:45:44.455552 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 0.9375
I0210 17:45:44.455564 27601 solver.cpp:244]     Train net output #1: loss = 0.0575714 (* 1 = 0.0575714 loss)
I0210 17:45:45.285504 27601 sgd_solver.cpp:106] Iteration 3660, lr = 1e-05
I0210 17:46:07.526223 27601 solver.cpp:228] Iteration 3680, loss = 0.00341154
I0210 17:46:07.526530 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:46:07.526546 27601 solver.cpp:244]     Train net output #1: loss = 0.00341111 (* 1 = 0.00341111 loss)
I0210 17:46:08.376389 27601 sgd_solver.cpp:106] Iteration 3680, lr = 1e-05
I0210 17:46:30.635761 27601 solver.cpp:228] Iteration 3700, loss = 0.0148242
I0210 17:46:30.635788 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:46:30.635797 27601 solver.cpp:244]     Train net output #1: loss = 0.0148237 (* 1 = 0.0148237 loss)
I0210 17:46:31.474817 27601 sgd_solver.cpp:106] Iteration 3700, lr = 1e-05
I0210 17:46:53.745252 27601 solver.cpp:228] Iteration 3720, loss = 0.00204604
I0210 17:46:53.745746 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:46:53.745784 27601 solver.cpp:244]     Train net output #1: loss = 0.00204562 (* 1 = 0.00204562 loss)
I0210 17:46:54.576503 27601 sgd_solver.cpp:106] Iteration 3720, lr = 1e-05
I0210 17:47:16.810405 27601 solver.cpp:228] Iteration 3740, loss = 0.00116031
I0210 17:47:16.810446 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:47:16.810457 27601 solver.cpp:244]     Train net output #1: loss = 0.00115988 (* 1 = 0.00115988 loss)
I0210 17:47:17.660810 27601 sgd_solver.cpp:106] Iteration 3740, lr = 1e-05
I0210 17:47:39.593233 27601 solver.cpp:337] Iteration 3760, Testing net (#0)
I0210 17:49:51.610366 27601 solver.cpp:404]     Test net output #0: acc_top_1 = 0.711943
I0210 17:49:51.610864 27601 solver.cpp:404]     Test net output #1: loss = 1.88904 (* 1 = 1.88904 loss)
I0210 17:49:51.933224 27601 solver.cpp:228] Iteration 3760, loss = 0.0163962
I0210 17:49:51.933270 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:49:51.933284 27601 solver.cpp:244]     Train net output #1: loss = 0.0163958 (* 1 = 0.0163958 loss)
I0210 17:49:52.780597 27601 sgd_solver.cpp:106] Iteration 3760, lr = 1e-05
I0210 17:50:15.450078 27601 solver.cpp:228] Iteration 3780, loss = 0.000865464
I0210 17:50:15.450112 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:50:15.450124 27601 solver.cpp:244]     Train net output #1: loss = 0.000865037 (* 1 = 0.000865037 loss)
I0210 17:50:16.280997 27601 sgd_solver.cpp:106] Iteration 3780, lr = 1e-05
I0210 17:50:38.371309 27601 solver.cpp:228] Iteration 3800, loss = 0.00372741
I0210 17:50:38.371825 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:50:38.371876 27601 solver.cpp:244]     Train net output #1: loss = 0.00372699 (* 1 = 0.00372699 loss)
I0210 17:50:39.215909 27601 sgd_solver.cpp:106] Iteration 3800, lr = 1e-05
I0210 17:51:02.055022 27601 solver.cpp:228] Iteration 3820, loss = 0.00451043
I0210 17:51:02.055063 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:51:02.055080 27601 solver.cpp:244]     Train net output #1: loss = 0.00451 (* 1 = 0.00451 loss)
I0210 17:51:02.896755 27601 sgd_solver.cpp:106] Iteration 3820, lr = 1e-05
I0210 17:51:25.798013 27601 solver.cpp:228] Iteration 3840, loss = 0.000357426
I0210 17:51:25.798496 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:51:25.798547 27601 solver.cpp:244]     Train net output #1: loss = 0.000357001 (* 1 = 0.000357001 loss)
I0210 17:51:26.629003 27601 sgd_solver.cpp:106] Iteration 3840, lr = 1e-05
I0210 17:51:48.880657 27601 solver.cpp:228] Iteration 3860, loss = 0.00509538
I0210 17:51:48.880697 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:51:48.880709 27601 solver.cpp:244]     Train net output #1: loss = 0.00509496 (* 1 = 0.00509496 loss)
I0210 17:51:49.736029 27601 sgd_solver.cpp:106] Iteration 3860, lr = 1e-05
I0210 17:52:11.967708 27601 solver.cpp:228] Iteration 3880, loss = 0.00130551
I0210 17:52:11.968142 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:52:11.968168 27601 solver.cpp:244]     Train net output #1: loss = 0.00130509 (* 1 = 0.00130509 loss)
I0210 17:52:12.804806 27601 sgd_solver.cpp:106] Iteration 3880, lr = 1e-05
I0210 17:52:35.067584 27601 solver.cpp:228] Iteration 3900, loss = 0.00214341
I0210 17:52:35.067641 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:52:35.067656 27601 solver.cpp:244]     Train net output #1: loss = 0.00214299 (* 1 = 0.00214299 loss)
I0210 17:52:35.904417 27601 sgd_solver.cpp:106] Iteration 3900, lr = 1e-05
I0210 17:52:58.169715 27601 solver.cpp:228] Iteration 3920, loss = 0.00287693
I0210 17:52:58.170289 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:52:58.170342 27601 solver.cpp:244]     Train net output #1: loss = 0.00287652 (* 1 = 0.00287652 loss)
I0210 17:52:59.015229 27601 sgd_solver.cpp:106] Iteration 3920, lr = 1e-05
I0210 17:53:21.958920 27601 solver.cpp:228] Iteration 3940, loss = 0.00491234
I0210 17:53:21.958961 27601 solver.cpp:244]     Train net output #0: acc_top_1 = 1
I0210 17:53:21.958973 27601 solver.cpp:244]     Train net output #1: loss = 0.00491192 (* 1 = 0.00491192 loss)
I0210 17:53:22.802649 27601 sgd_solver.cpp:106] Iteration 3940, lr = 1e-05
I0210 17:53:30.902412 27601 solver.cpp:454] Snapshotting to binary proto file /opt/luojh/Net-Compression/value_sum/CUB200/1_ft_avg_vgg/avg_vgg/snapshot/_iter_3948.caffemodel
I0210 17:53:31.248397 27601 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /opt/luojh/Net-Compression/value_sum/CUB200/1_ft_avg_vgg/avg_vgg/snapshot/_iter_3948.solverstate
I0210 17:53:31.317525 27601 solver.cpp:337] Iteration 3948, Testing net (#0)
I0210 17:55:43.247287 27601 solver.cpp:404]     Test net output #0: acc_top_1 = 0.711771
I0210 17:55:43.247624 27601 solver.cpp:404]     Test net output #1: loss = 1.89563 (* 1 = 1.89563 loss)
I0210 17:55:43.247634 27601 solver.cpp:322] Optimization Done.
I0210 17:55:43.521700 27601 caffe.cpp:222] Optimization Done.
